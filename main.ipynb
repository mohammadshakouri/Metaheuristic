{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook Overview: Rule-Based Trading with Metaheuristic Rule Discovery**\n",
    "\n",
    "This notebook presents a complete demonstration of a **rule-based trading system** applied to Ethereum price data. The objective is to illustrate how **Genetic Algorithms (GA)** can be used to *automatically discover interpretable IF–THEN trading rules* based on engineered features from **Phase 1 of the course** .\n",
    "\n",
    "The implementation follows the conceptual framework introduced in the accompanying lecture materials on **Rule Discovery with Metaheuristics** .\n",
    "\n",
    "---\n",
    "\n",
    "## **Purpose of the Notebook**\n",
    "\n",
    "The notebook serves as a educational example demonstrating:\n",
    "\n",
    "1. **How trading rules are encoded as chromosomes** within a GA.\n",
    "2. **How conditions, actions, TP/SL levels, and position sizing are represented genetically.**\n",
    "3. **How a rule list is decoded and executed via a backtesting engine.**\n",
    "4. **How the GA iteratively improves candidate rule sets** using fitness feedback from historical performance.\n",
    "\n",
    "Although the demonstration uses only a subset of features, students may extend the system to incorporate the full set of engineered indicators produced in Phase 1.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chromosome Structure and Representation**\n",
    "\n",
    "Each chromosome represents a **complete ordered rule list**, where:\n",
    "\n",
    "* Each rule consists of multiple **conditions**, specifying a feature, operator, and threshold.\n",
    "* Each rule also encodes its **action parameters**:\n",
    "\n",
    "  * Take-profit (TP),\n",
    "  * Stop-loss (SL),\n",
    "  * **Fraction of capital allocated to the trade** (position size).\n",
    "* Activation flags control whether a rule or condition is included in the effective strategy.\n",
    "\n",
    "The genetic representation enables exploration of a very large combinational search space while retaining **transparent, human-readable rule structures** once decoded.\n",
    "\n",
    "---\n",
    "\n",
    "## **Training Data and Features**\n",
    "\n",
    "For this demonstration, we use only a small set of the available features to keep the example focused and computationally manageable.\n",
    "However, students are encouraged to:\n",
    "\n",
    "* Use **all available engineered features**,\n",
    "* Modify or extend the chromosome structure,\n",
    "* Experiment with different operator sets, thresholds, or rule depths.\n",
    "\n",
    "The system is fully modular, and feature selection is handled implicitly via the genetic encoding.\n",
    "\n",
    "---\n",
    "\n",
    "## **Optimization and Fitness Function**\n",
    "\n",
    "The GA is trained exclusively on the **training dataset**.\n",
    "The objective function (fitness) is defined as:\n",
    "\n",
    "> **Final equity obtained after backtesting the rule set**, starting with an initial capital of $1000.\n",
    "\n",
    "This formulation incorporates:\n",
    "\n",
    "* Profitability of trades,\n",
    "* Trading frequency,\n",
    "* Position sizing decisions,\n",
    "* Compounding through equity updates.\n",
    "\n",
    "After training, students must evaluate their discovered rule sets on the **separate test dataset** to assess out-of-sample performance and detect overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Student Instructions**\n",
    "\n",
    "* You may run this notebook directly in **Google Colab**, but remember to mount your Google Drive before accessing datasets.\n",
    "* All configuration parameters (e.g., population size, mutation rates, TP/SL ranges, position-size bounds) can be modified to explore different design choices.\n",
    "* The implementation is modular; students may:\n",
    "\n",
    "  * Add new features,\n",
    "  * Adjust how rules are represented,\n",
    "  * Implement alternative fitness functions,\n",
    "  * Replace GA with other metaheuristic algorithms such as PSO or DE.\n",
    "\n",
    "---\n",
    "\n",
    "## **Educational Goals**\n",
    "\n",
    "By working through this notebook, you will gain hands-on understanding of:\n",
    "\n",
    "* How rule-based trading systems are formalized and optimized,\n",
    "* How metaheuristic methods operate on structured, interpretable solutions,\n",
    "* How backtesting interacts with rule logic, signal generation, and position management,\n",
    "* How to evaluate trading strategies rigorously using both train and test datasets.\n",
    "\n",
    "This forms the foundation for the **Phase 2 Rule Discovery Project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwFOr1myb2ie",
    "outputId": "6fe2ad62-bf85-4b9f-cd5a-a28ce937d1ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "DGriP3ayPLD_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "xqnmtLloQizq"
   },
   "outputs": [],
   "source": [
    "# === CONFIG: rule structure, GA, and trading ===\n",
    "\n",
    "MAX_RULES = 3        # N (max rules in the rule list)\n",
    "MAX_CONDS = 2         # K (max conditions per rule)\n",
    "\n",
    "TP_MIN, TP_MAX = 0.02, 0.05   # 2% .. 5%\n",
    "SL_MIN, SL_MAX = 0.06, 0.08   # 6% .. 8%\n",
    "\n",
    "STARTING_CAPITAL = 1000.0    # starting money for the strategy\n",
    "\n",
    "POS_MIN_FRAC = 0.10          # 10% of capital per trade (min)\n",
    "POS_MAX_FRAC = 0.40          # 40% of capital per trade (max)\n",
    "\n",
    "POP_SIZE = 10\n",
    "N_GENERATIONS = 10\n",
    "TOURNAMENT_SIZE = 5\n",
    "CROSSOVER_RATE = 0.85\n",
    "MUTATION_RATE = 0.05   # base mutation probability per gene\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_feature(feature_cols, patterns):\n",
    "    for p in patterns:\n",
    "        rgx = re.compile(p, re.I)\n",
    "        for col in feature_cols:\n",
    "            if rgx.search(col):\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "def resolve_key_features(feature_cols):\n",
    "    ma_fast = pick_feature(feature_cols, [r'\\bma\\b.*(5|7|9|10|12|14)', r'(sma|ema).*(5|7|9|10|12|14)'])\n",
    "    ma_slow = pick_feature(feature_cols, [r'\\bma\\b.*(20|21|24|25|30)', r'(sma|ema).*(20|21|24|25|30)'])\n",
    "    rsi     = pick_feature(feature_cols, [r'\\brsi\\b'])\n",
    "    ret1    = pick_feature(feature_cols, [r'\\bret(urn)?_?1\\b', r'\\breturn_1\\b', r'\\bchg_1\\b'])\n",
    "    retN    = pick_feature(feature_cols, [r'\\bret(urn)?_?(5|10|14)\\b', r'\\breturn_(5|10|14)\\b'])\n",
    "    vol     = pick_feature(feature_cols, [r'\\bvol\\b', r'vol', r'atr', r'std', r'volatility'])\n",
    "\n",
    "    return {\n",
    "        \"ma_fast\": ma_fast,\n",
    "        \"ma_slow\": ma_slow,\n",
    "        \"rsi\": rsi,\n",
    "        \"ret1\": ret1,\n",
    "        \"retN\": retN,\n",
    "        \"vol\": vol\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "0509KhbyQmMA"
   },
   "outputs": [],
   "source": [
    "# === 1. Load ETH data with engineered features ===\n",
    "\n",
    "def load_eth_features(csv_path: str,\n",
    "                      feature_cols: List[str],\n",
    "                      close_col: str = \"close\"\n",
    "                      ) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load ETH OHLCV + engineered features.\n",
    "    We keep only 'close' and selected feature columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV containing at least 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        Subset of ~50 features you want to use in the demo.\n",
    "    close_col : str\n",
    "        Name of the close price column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame indexed by time with 'close' and selected features.\n",
    "    feature_cols_used : list of str\n",
    "        The actual feature columns we keep (intersection of requested + available).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=True, index_col=0)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    if close_col.lower() not in df.columns:\n",
    "        raise ValueError(f\"Close column '{close_col}' not found in data.\")\n",
    "\n",
    "    # Intersect requested features with available columns\n",
    "    feature_cols_lower = [c.lower() for c in feature_cols]\n",
    "    available_features = [c for c in feature_cols_lower if c in df.columns]\n",
    "\n",
    "    if len(available_features) == 0:\n",
    "        raise ValueError(\"None of the requested feature columns are present in the data.\")\n",
    "\n",
    "    cols_to_keep = [close_col.lower()] + available_features\n",
    "    df = df[cols_to_keep].sort_index()\n",
    "\n",
    "    return df, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "J0q2R-qiS3e8"
   },
   "outputs": [],
   "source": [
    "# === 2. Gene and Rule structures (phenotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Condition:\n",
    "    # active: bool\n",
    "    feature_idx: int\n",
    "    operator: str      # \"<\" or \">\"\n",
    "    q: float    # ADD FOR QUANTILE\n",
    "    threshold: float = None   # numeric threshold\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rule:\n",
    "    # active: bool\n",
    "    conditions: List[Condition]\n",
    "    side: str          # \"BUY\" or \"SELL\"\n",
    "    tp: float          # take-profit as decimal (e.g. 0.03 for 3%)\n",
    "    sl: float          # stop-loss as decimal\n",
    "    size_frac: float   # fraction of current capital to allocate (0.0–1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "3bN_E5mZTHEg"
   },
   "outputs": [],
   "source": [
    "# === 2b. Chromosome representation (genotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Chromosome:\n",
    "    # Rule-level genes\n",
    "    rule_active: np.ndarray      # (MAX_RULES,)  {0,1}\n",
    "    side_gene: np.ndarray        # (MAX_RULES,)  {0,1}  0=BUY, 1=SELL\n",
    "    tp_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    sl_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    size_gene: np.ndarray        # (MAX_RULES,)  [0,1]  --> position size fraction\n",
    "\n",
    "    # Condition-level genes\n",
    "    cond_active: np.ndarray      # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    feature_idx_gene: np.ndarray # (MAX_RULES, MAX_CONDS)\n",
    "    operator_gene: np.ndarray    # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    # threshold_gene: np.ndarray   # (MAX_RULES, MAX_CONDS)  [0,1]\n",
    "    q_gene: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "-VRFr0mrTMJI"
   },
   "outputs": [],
   "source": [
    "# === 3. Mapping genes to actual TP/SL and thresholds ===\n",
    "\n",
    "def map_tp_gene(tp_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to TP% in [TP_MIN, TP_MAX].\"\"\"\n",
    "    return TP_MIN + tp_gene * (TP_MAX - TP_MIN)\n",
    "\n",
    "\n",
    "def map_sl_gene(sl_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to SL% in [SL_MIN, SL_MAX].\"\"\"\n",
    "    return SL_MIN + sl_gene * (SL_MAX - SL_MIN)\n",
    "\n",
    "\n",
    "def map_size_gene(size_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map [0,1] size_gene to a fraction of capital to allocate per trade.\n",
    "    For example, POS_MIN_FRAC=0.05, POS_MAX_FRAC=0.5 => 5%..50%.\n",
    "    \"\"\"\n",
    "    return POS_MIN_FRAC + size_gene * (POS_MAX_FRAC - POS_MIN_FRAC)\n",
    "\n",
    "\n",
    "def map_operator_gene(op_gene: int) -> str:\n",
    "    \"\"\"0 -> '<', 1 -> '>'.\"\"\"\n",
    "    return \"<\" if op_gene == 0 else \">\"\n",
    "\n",
    "\n",
    "def map_threshold_gene_to_value(feature_series: pd.Series, thr_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map a [0,1] threshold_gene to a numeric threshold using feature quantiles.\n",
    "\n",
    "    thr_gene ~ 0.0 => low quantile (e.g. oversold RSI)\n",
    "    thr_gene ~ 1.0 => high quantile (e.g. overbought RSI)\n",
    "    \"\"\"\n",
    "    # np.nanquantile handles NaNs gracefully\n",
    "    return float(np.nanquantile(feature_series.values, thr_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_condition_thresholds(\n",
    "    rules,\n",
    "    df_reference: pd.DataFrame,\n",
    "    feature_cols\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute real thresholds using quantiles from df_reference only.\n",
    "    Prevents data leakage.\n",
    "    \"\"\"\n",
    "    for r in rules:\n",
    "        for cond in r.conditions:\n",
    "            feat = feature_cols[cond.feature_idx]\n",
    "            series = df_reference[feat].dropna()\n",
    "\n",
    "            if len(series) == 0:\n",
    "                cond.threshold = None\n",
    "                continue\n",
    "\n",
    "            q = min(max(cond.q, 0.01), 0.99)\n",
    "            cond.threshold = float(series.quantile(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "b6hGCuyETa8e"
   },
   "outputs": [],
   "source": [
    "# === Decode Chromosome to Rule List (Quantile-based) ===\n",
    "\n",
    "def decode_chromosome(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> List[Rule]:\n",
    "    \"\"\"\n",
    "    Decode chromosome into a list of Rule objects.\n",
    "    IMPORTANT:\n",
    "    - This function does NOT compute numeric thresholds.\n",
    "    - It only assigns quantile genes (q).\n",
    "    - Real thresholds are computed later using compute_condition_thresholds().\n",
    "    \"\"\"\n",
    "\n",
    "    rules: List[Rule] = []\n",
    "\n",
    "    for r in range(MAX_RULES):\n",
    "        if chrom.rule_active[r] == 0:\n",
    "            continue\n",
    "\n",
    "        # --- rule-level genes ---\n",
    "        side = \"BUY\" if chrom.side_gene[r] == 0 else \"SELL\"\n",
    "        tp = map_tp_gene(chrom.tp_gene[r])\n",
    "        sl = map_sl_gene(chrom.sl_gene[r])\n",
    "        size_frac = map_size_gene(chrom.size_gene[r])\n",
    "\n",
    "        conds: List[Condition] = []\n",
    "\n",
    "        for c in range(MAX_CONDS):\n",
    "            if chrom.cond_active[r, c] == 0:\n",
    "                continue\n",
    "\n",
    "            feat_idx = int(chrom.feature_idx_gene[r, c]) % len(feature_cols)\n",
    "            op = map_operator_gene(int(chrom.operator_gene[r, c]))\n",
    "\n",
    "            # ⭐ Quantile gene (NOT numeric threshold)\n",
    "            q = float(chrom.q_gene[r, c])   # اگر اسم را عوض نکردی: threshold_gene\n",
    "\n",
    "            conds.append(\n",
    "                Condition(\n",
    "                    feature_idx=feat_idx,\n",
    "                    operator=op,\n",
    "                    q=q,              # quantile ∈ (0,1)\n",
    "                    threshold=None    # computed later\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # discard empty rules\n",
    "        if len(conds) == 0:\n",
    "            continue\n",
    "\n",
    "        rules.append(\n",
    "            Rule(\n",
    "                conditions=conds,\n",
    "                side=side,\n",
    "                tp=tp,\n",
    "                sl=sl,\n",
    "                size_frac=size_frac,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "5CoyXYyWTxAQ"
   },
   "outputs": [],
   "source": [
    "def rule_fires(\n",
    "    rule: Rule,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    t: int\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if a rule fires at row index t.\n",
    "    All conditions must be true.\n",
    "\n",
    "    Quantile-based note:\n",
    "    - cond.threshold MUST be pre-computed (e.g., by compute_condition_thresholds).\n",
    "    - If threshold is None, rule does not fire (prevents leakage / undefined behavior).\n",
    "    \"\"\"\n",
    "    row = df.iloc[t]\n",
    "\n",
    "    for cond in rule.conditions:\n",
    "        # threshold must exist\n",
    "        thr = getattr(cond, \"threshold\", None)\n",
    "        if thr is None or np.isnan(thr):\n",
    "            return False\n",
    "\n",
    "        feat_name = feature_cols[cond.feature_idx]\n",
    "        x = row[feat_name]\n",
    "\n",
    "        # missing feature => don't fire\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return False\n",
    "\n",
    "        op = cond.operator\n",
    "        if op == \"<\":\n",
    "            if not (x < thr):\n",
    "                return False\n",
    "        elif op == \">\":\n",
    "            if not (x > thr):\n",
    "                return False\n",
    "        else:\n",
    "            # unknown operator => safe fail\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "oPAdngejVHJ1"
   },
   "outputs": [],
   "source": [
    "def backtest_rule_list(\n",
    "    rules: List[Rule],\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    starting_capital: float = STARTING_CAPITAL\n",
    ") -> Tuple[List[float], float, int]:\n",
    "    \"\"\"\n",
    "    Backtest a rule list with capital and position sizing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    equity_curve : list of float\n",
    "        True equity over time (incremental)\n",
    "    final_equity : float\n",
    "        Final money after all trades\n",
    "    n_trades : int\n",
    "        Number of closed trades\n",
    "    \"\"\"\n",
    "    if len(rules) == 0:\n",
    "        return [starting_capital], starting_capital, 0\n",
    "\n",
    "    close = df[\"close\"].values\n",
    "    n = len(df)\n",
    "\n",
    "    equity = float(starting_capital)\n",
    "    equity_curve = [equity]\n",
    "\n",
    "    position = 0          # 0 = flat, +1 = long, -1 = short\n",
    "    entry_price = None\n",
    "    entry_rule: Optional[Rule] = None\n",
    "    entry_capital = None\n",
    "\n",
    "    n_trades = 0\n",
    "\n",
    "    for t in range(n):\n",
    "        price = close[t]\n",
    "        if np.isnan(price):\n",
    "            equity_curve.append(equity)\n",
    "            continue\n",
    "\n",
    "        if position == 0:\n",
    "            # --- FLAT: look for entry ---\n",
    "            for rule in rules:\n",
    "                if rule_fires(rule, df, feature_cols, t):\n",
    "                    size_frac = rule.size_frac\n",
    "                    trade_capital = equity * size_frac\n",
    "\n",
    "                    if trade_capital <= 0:\n",
    "                        break\n",
    "\n",
    "                    position = 1 if rule.side == \"BUY\" else -1\n",
    "                    entry_price = price\n",
    "                    entry_rule = rule\n",
    "                    entry_capital = trade_capital\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            # --- IN POSITION: manage trade ---\n",
    "            ret = position * (price / entry_price - 1.0)\n",
    "\n",
    "            tp_hit = ret >= entry_rule.tp\n",
    "            sl_hit = ret <= -entry_rule.sl\n",
    "\n",
    "            if tp_hit or sl_hit:\n",
    "                pnl = ret * entry_capital\n",
    "                equity += pnl\n",
    "\n",
    "                position = 0\n",
    "                entry_price = None\n",
    "                entry_rule = None\n",
    "                entry_capital = None\n",
    "\n",
    "                n_trades += 1\n",
    "\n",
    "        equity_curve.append(equity)\n",
    "\n",
    "    # --- force close at last price (important!) ---\n",
    "    if position != 0 and entry_price is not None and entry_capital is not None:\n",
    "        final_price = close[-1]\n",
    "        if not np.isnan(final_price):\n",
    "            ret = position * (final_price / entry_price - 1.0)\n",
    "            pnl = ret * entry_capital\n",
    "            equity += pnl\n",
    "            equity_curve[-1] = equity\n",
    "            n_trades += 1\n",
    "\n",
    "    return equity_curve, equity, n_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "-YF-8MCYVase"
   },
   "outputs": [],
   "source": [
    "def compute_fitness(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Walk-forward + Quantile-based fitness.\n",
    "    Robust against overfitting and scale drift.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Decode chromosome → rules (WITHOUT numeric thresholds)\n",
    "    rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "    # 2) Walk-forward split\n",
    "    n = len(df)\n",
    "    if n < 100:  # safety guard\n",
    "        return -1e6\n",
    "\n",
    "    split = int(0.7 * n)\n",
    "    df_A = df.iloc[:split]\n",
    "    df_B = df.iloc[split:]\n",
    "\n",
    "    # 3) ⭐ Compute REAL thresholds from df_A ONLY (quantile-based)\n",
    "    compute_condition_thresholds(rules, df_A, feature_cols)\n",
    "\n",
    "    # 4) Backtest on A (train part)\n",
    "    eq_A_curve, final_A, trades_A = backtest_rule_list(\n",
    "        rules, df_A, feature_cols\n",
    "    )\n",
    "\n",
    "    # 5) Backtest on B (forward / pseudo-test)\n",
    "    eq_B_curve, final_B, trades_B = backtest_rule_list(\n",
    "        rules, df_B, feature_cols\n",
    "    )\n",
    "\n",
    "    # 6) Hard rejection (no-trade or degenerate strategies)\n",
    "    if trades_A == 0 or trades_B == 0:\n",
    "        return -1e6\n",
    "\n",
    "    # 7) Drawdown on B only (future-facing risk)\n",
    "    eq_B_curve = np.asarray(eq_B_curve, dtype=float)\n",
    "    running_max = np.maximum.accumulate(eq_B_curve)\n",
    "    drawdowns = (running_max - eq_B_curve) / np.clip(running_max, 1e-12, None)\n",
    "    max_dd_B = float(np.max(drawdowns))\n",
    "\n",
    "    # ---------------- penalties ----------------\n",
    "\n",
    "    # (1) drawdown penalty (soft, realistic)\n",
    "    LAMBDA_DD = 0.4\n",
    "    penalty_dd = LAMBDA_DD * max_dd_B * STARTING_CAPITAL\n",
    "\n",
    "    # (2) complexity penalty (rules + conditions)\n",
    "    n_rules = len(rules)\n",
    "    n_conds = sum(\n",
    "        len(r.conditions)\n",
    "        for r in rules\n",
    "        if hasattr(r, \"conditions\") and r.conditions is not None\n",
    "    )\n",
    "    penalty_complexity = 1.2 * n_rules + 0.4 * n_conds\n",
    "\n",
    "    # (3) trade-count pressure (soft, on B only)\n",
    "    penalty_trades = 0.0\n",
    "    if trades_B > 120:\n",
    "        penalty_trades += 2.0 * (trades_B - 120)\n",
    "    elif trades_B < 10:\n",
    "        penalty_trades += 50.0\n",
    "\n",
    "    # 8) Final fitness (future weighted more)\n",
    "    fitness = (\n",
    "        0.4 * final_A\n",
    "        + 0.6 * final_B\n",
    "        - penalty_dd\n",
    "        - penalty_complexity\n",
    "        - penalty_trades\n",
    "    )\n",
    "\n",
    "    return float(fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "kWiZwprFVkN8"
   },
   "outputs": [],
   "source": [
    "# === 6. GA: initialization ===\n",
    "\n",
    "def random_chromosome(n_features: int) -> Chromosome:\n",
    "    rule_active = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    if rule_active.sum() == 0:\n",
    "        rule_active[np.random.randint(0, MAX_RULES)] = 1\n",
    "\n",
    "    side_gene = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    tp_gene = np.random.rand(MAX_RULES)\n",
    "    sl_gene = np.random.rand(MAX_RULES)\n",
    "    size_gene = np.random.rand(MAX_RULES)  # NEW: position size genes in [0,1]\n",
    "\n",
    "    cond_active = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    for r in range(MAX_RULES):\n",
    "        if rule_active[r] == 1 and cond_active[r].sum() == 0:\n",
    "            cond_active[r, np.random.randint(0, MAX_CONDS)] = 1\n",
    "\n",
    "    feature_idx_gene = np.random.randint(0, n_features, size=(MAX_RULES, MAX_CONDS))\n",
    "    operator_gene = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    q_gene = np.random.rand(MAX_RULES, MAX_CONDS)\n",
    "\n",
    "    return Chromosome(\n",
    "        rule_active=rule_active,\n",
    "        side_gene=side_gene,\n",
    "        tp_gene=tp_gene,\n",
    "        sl_gene=sl_gene,\n",
    "        size_gene=size_gene,\n",
    "        cond_active=cond_active,\n",
    "        feature_idx_gene=feature_idx_gene,\n",
    "        operator_gene=operator_gene,\n",
    "        q_gene=q_gene,   # ⭐\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_index(feature_cols, name):\n",
    "    return feature_cols.index(name)\n",
    "\n",
    "def make_empty_chromosome(n_features: int) -> Chromosome:\n",
    "    return random_chromosome(n_features)  # یا نسخه‌ی صفر شده اگر داری\n",
    "\n",
    "def set_condition(chrom, r, c, feat_idx, op, q):\n",
    "    chrom.cond_active[r, c] = 1\n",
    "    chrom.feature_idx_gene[r, c] = feat_idx\n",
    "    chrom.operator_gene[r, c] = 0 if op == \"<\" else 1\n",
    "    chrom.q_gene[r, c] = float(np.clip(q, 0.05, 0.95))\n",
    "\n",
    "def set_rule_action(chrom, r, side, tp, sl, size):\n",
    "    chrom.rule_active[r] = 1\n",
    "    chrom.side_gene[r] = 0 if side == \"BUY\" else 1\n",
    "    # فرض: map_tp_gene از 0..1 به tp واقعی می‌رود\n",
    "    # پس باید inverse mapping داشته باشی یا tp_gene را مستقیم رند بگذاری\n",
    "    chrom.tp_gene[r] = np.clip(tp, 0.0, 1.0)   # اگر tp_gene مستقیم نیست، پایین توضیح می‌دم\n",
    "    chrom.sl_gene[r] = np.clip(sl, 0.0, 1.0)\n",
    "    chrom.size_gene[r] = np.clip(size, 0.0, 1.0)\n",
    "\n",
    "\n",
    "\n",
    "def seeded_population(df, feature_cols, pop_size, seed_ratio=0.9):\n",
    "    n_features = len(feature_cols)\n",
    "    feats = resolve_key_features(feature_cols)\n",
    "\n",
    "    n_seed = int(pop_size * seed_ratio)\n",
    "    n_rand = pop_size - n_seed\n",
    "\n",
    "    population = []\n",
    "\n",
    "    # --- Seed templates ---\n",
    "    templates = []\n",
    "\n",
    "    # Mean reversion via RSI\n",
    "    if feats[\"rsi\"] is not None:\n",
    "        rsi_idx = feature_index(feature_cols, feats[\"rsi\"])\n",
    "        templates += [\n",
    "            (\"BUY\",  [(rsi_idx, \"<\", 0.20)], 0.02, 0.01, 0.10),\n",
    "            (\"SELL\", [(rsi_idx, \">\", 0.80)], 0.02, 0.01, 0.10),\n",
    "        ]\n",
    "\n",
    "    # Trend filter via MA fast/slow (اگر هر دو وجود دارند)\n",
    "    if feats[\"ma_fast\"] is not None and feats[\"ma_slow\"] is not None:\n",
    "        fast_idx = feature_index(feature_cols, feats[\"ma_fast\"])\n",
    "        slow_idx = feature_index(feature_cols, feats[\"ma_slow\"])\n",
    "        # تقریبی: fast بالا و slow پایین برای BUY، برعکس برای SELL\n",
    "        templates += [\n",
    "            (\"BUY\",  [(fast_idx, \">\", 0.60), (slow_idx, \"<\", 0.60)], 0.025, 0.015, 0.12),\n",
    "            (\"SELL\", [(fast_idx, \"<\", 0.40), (slow_idx, \">\", 0.40)], 0.025, 0.015, 0.12),\n",
    "        ]\n",
    "\n",
    "    # Momentum via ret1/retN\n",
    "    if feats[\"ret1\"] is not None:\n",
    "        ret1_idx = feature_index(feature_cols, feats[\"ret1\"])\n",
    "        templates += [\n",
    "            (\"BUY\",  [(ret1_idx, \">\", 0.70)], 0.02, 0.015, 0.10),\n",
    "            (\"SELL\", [(ret1_idx, \"<\", 0.30)], 0.02, 0.015, 0.10),\n",
    "        ]\n",
    "    if feats[\"retN\"] is not None:\n",
    "        retN_idx = feature_index(feature_cols, feats[\"retN\"])\n",
    "        templates += [\n",
    "            (\"BUY\",  [(retN_idx, \">\", 0.70)], 0.03, 0.02, 0.12),\n",
    "            (\"SELL\", [(retN_idx, \"<\", 0.30)], 0.03, 0.02, 0.12),\n",
    "        ]\n",
    "\n",
    "    # Volatility filter (optional): keep vol in mid quantiles\n",
    "    if feats[\"vol\"] is not None:\n",
    "        vol_idx = feature_index(feature_cols, feats[\"vol\"])\n",
    "        # به عنوان شرط دوم/سوم اضافه می‌کنیم\n",
    "        vol_filter = [(vol_idx, \">\", 0.20), (vol_idx, \"<\", 0.80)]\n",
    "    else:\n",
    "        vol_filter = []\n",
    "\n",
    "    if len(templates) == 0:\n",
    "        # fallback: no recognized features → all random\n",
    "        return [random_chromosome(n_features) for _ in range(pop_size)]\n",
    "\n",
    "    # --- build seeded chromosomes ---\n",
    "    for i in range(n_seed):\n",
    "        side, conds, tp, sl, size = templates[i % len(templates)]\n",
    "        chrom = random_chromosome(n_features)  # شروع از رند برای تنوع ژن‌های غیرمستقیم\n",
    "        # یک rule بسازیم در اسلات 0\n",
    "        r = 0\n",
    "        chrom.rule_active[:] = 0\n",
    "        chrom.cond_active[:, :] = 0\n",
    "\n",
    "        set_rule_action(chrom, r, side, tp=np.random.rand(), sl=np.random.rand(), size=np.random.rand())\n",
    "        # tp/sl/size را بعداً با map به مقادیر معقول constrain می‌کنیم در mutation/fitness\n",
    "\n",
    "        # conditions\n",
    "        cslot = 0\n",
    "        for (feat_idx, op, q) in conds:\n",
    "            if cslot >= MAX_CONDS:\n",
    "                break\n",
    "            set_condition(chrom, r, cslot, feat_idx, op, q)\n",
    "            cslot += 1\n",
    "\n",
    "        # volatility filter را اگر جا هست اضافه کن\n",
    "        for (feat_idx, op, q) in vol_filter:\n",
    "            if cslot >= MAX_CONDS:\n",
    "                break\n",
    "            set_condition(chrom, r, cslot, feat_idx, op, q)\n",
    "            cslot += 1\n",
    "\n",
    "        # بقیه ruleها را خاموش نگه دار یا با احتمال کم روشن کن\n",
    "        population.append(chrom)\n",
    "\n",
    "    # --- add random remainder ---\n",
    "    population += [random_chromosome(n_features) for _ in range(n_rand)]\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "xS7M2nQXVop2"
   },
   "outputs": [],
   "source": [
    "# === 6b. Parent selection (tournament) ===\n",
    "\n",
    "def tournament_selection(population: List[Chromosome],\n",
    "                         fitnesses: List[float],\n",
    "                         k: int = TOURNAMENT_SIZE) -> Chromosome:\n",
    "    \"\"\"\n",
    "    Tournament selection: pick k random individuals, return the best.\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(population), size=k, replace=False)\n",
    "    best_idx = idxs[0]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "    for i in idxs[1:]:\n",
    "        if fitnesses[i] > best_fit:\n",
    "            best_fit = fitnesses[i]\n",
    "            best_idx = i\n",
    "    return population[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "gIe7D7nSVqa7"
   },
   "outputs": [],
   "source": [
    "def crossover(\n",
    "    parent1: Chromosome,\n",
    "    parent2: Chromosome\n",
    ") -> Tuple[Chromosome, Chromosome]:\n",
    "    \"\"\"\n",
    "    Rule-aware uniform crossover with gentle condition mixing.\n",
    "    Quantile-aware (uses q_gene instead of threshold_gene).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- no crossover → clone ----------\n",
    "    if np.random.rand() >= CROSSOVER_RATE:\n",
    "        child1 = Chromosome(\n",
    "            rule_active=parent1.rule_active.copy(),\n",
    "            side_gene=parent1.side_gene.copy(),\n",
    "            tp_gene=parent1.tp_gene.copy(),\n",
    "            sl_gene=parent1.sl_gene.copy(),\n",
    "            size_gene=parent1.size_gene.copy(),\n",
    "            cond_active=parent1.cond_active.copy(),\n",
    "            feature_idx_gene=parent1.feature_idx_gene.copy(),\n",
    "            operator_gene=parent1.operator_gene.copy(),\n",
    "            q_gene=parent1.q_gene.copy(),\n",
    "        )\n",
    "        child2 = Chromosome(\n",
    "            rule_active=parent2.rule_active.copy(),\n",
    "            side_gene=parent2.side_gene.copy(),\n",
    "            tp_gene=parent2.tp_gene.copy(),\n",
    "            sl_gene=parent2.sl_gene.copy(),\n",
    "            size_gene=parent2.size_gene.copy(),\n",
    "            cond_active=parent2.cond_active.copy(),\n",
    "            feature_idx_gene=parent2.feature_idx_gene.copy(),\n",
    "            operator_gene=parent2.operator_gene.copy(),\n",
    "            q_gene=parent2.q_gene.copy(),\n",
    "        )\n",
    "        return child1, child2\n",
    "\n",
    "    # ---------- create empty children ----------\n",
    "    child1 = Chromosome(\n",
    "        rule_active=np.zeros_like(parent1.rule_active),\n",
    "        side_gene=np.zeros_like(parent1.side_gene),\n",
    "        tp_gene=np.zeros_like(parent1.tp_gene),\n",
    "        sl_gene=np.zeros_like(parent1.sl_gene),\n",
    "        size_gene=np.zeros_like(parent1.size_gene),\n",
    "        cond_active=np.zeros_like(parent1.cond_active),\n",
    "        feature_idx_gene=np.zeros_like(parent1.feature_idx_gene),\n",
    "        operator_gene=np.zeros_like(parent1.operator_gene),\n",
    "        q_gene=np.zeros_like(parent1.q_gene),\n",
    "    )\n",
    "\n",
    "    child2 = Chromosome(\n",
    "        rule_active=np.zeros_like(parent1.rule_active),\n",
    "        side_gene=np.zeros_like(parent1.side_gene),\n",
    "        tp_gene=np.zeros_like(parent1.tp_gene),\n",
    "        sl_gene=np.zeros_like(parent1.sl_gene),\n",
    "        size_gene=np.zeros_like(parent1.size_gene),\n",
    "        cond_active=np.zeros_like(parent1.cond_active),\n",
    "        feature_idx_gene=np.zeros_like(parent1.feature_idx_gene),\n",
    "        operator_gene=np.zeros_like(parent1.operator_gene),\n",
    "        q_gene=np.zeros_like(parent1.q_gene),\n",
    "    )\n",
    "\n",
    "    # ---------- rule-level uniform crossover ----------\n",
    "    for r in range(MAX_RULES):\n",
    "        if np.random.rand() < 0.5:\n",
    "            src1, src2 = parent1, parent2\n",
    "        else:\n",
    "            src1, src2 = parent2, parent1\n",
    "\n",
    "        # rule-level genes\n",
    "        child1.rule_active[r] = src1.rule_active[r]\n",
    "        child1.side_gene[r]   = src1.side_gene[r]\n",
    "        child1.tp_gene[r]     = src1.tp_gene[r]\n",
    "        child1.sl_gene[r]     = src1.sl_gene[r]\n",
    "        child1.size_gene[r]   = src1.size_gene[r]\n",
    "\n",
    "        child2.rule_active[r] = src2.rule_active[r]\n",
    "        child2.side_gene[r]   = src2.side_gene[r]\n",
    "        child2.tp_gene[r]     = src2.tp_gene[r]\n",
    "        child2.sl_gene[r]     = src2.sl_gene[r]\n",
    "        child2.size_gene[r]   = src2.size_gene[r]\n",
    "\n",
    "        # ---------- condition-level gentle mixing ----------\n",
    "        for c in range(MAX_CONDS):\n",
    "\n",
    "            # ---- child1 ----\n",
    "            if child1.rule_active[r] == 0:\n",
    "                # inactive rule → copy directly\n",
    "                child1.cond_active[r, c]      = src1.cond_active[r, c]\n",
    "                child1.feature_idx_gene[r, c] = src1.feature_idx_gene[r, c]\n",
    "                child1.operator_gene[r, c]    = src1.operator_gene[r, c]\n",
    "                child1.q_gene[r, c]           = src1.q_gene[r, c]\n",
    "            else:\n",
    "                donor = src1 if np.random.rand() < 0.7 else src2\n",
    "                child1.cond_active[r, c]      = donor.cond_active[r, c]\n",
    "                child1.feature_idx_gene[r, c] = donor.feature_idx_gene[r, c]\n",
    "                child1.operator_gene[r, c]    = donor.operator_gene[r, c]\n",
    "                child1.q_gene[r, c]           = donor.q_gene[r, c]\n",
    "\n",
    "            # ---- child2 ----\n",
    "            if child2.rule_active[r] == 0:\n",
    "                child2.cond_active[r, c]      = src2.cond_active[r, c]\n",
    "                child2.feature_idx_gene[r, c] = src2.feature_idx_gene[r, c]\n",
    "                child2.operator_gene[r, c]    = src2.operator_gene[r, c]\n",
    "                child2.q_gene[r, c]           = src2.q_gene[r, c]\n",
    "            else:\n",
    "                donor = src2 if np.random.rand() < 0.7 else src1\n",
    "                child2.cond_active[r, c]      = donor.cond_active[r, c]\n",
    "                child2.feature_idx_gene[r, c] = donor.feature_idx_gene[r, c]\n",
    "                child2.operator_gene[r, c]    = donor.operator_gene[r, c]\n",
    "                child2.q_gene[r, c]           = donor.q_gene[r, c]\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "Q8WP6o1zVspn"
   },
   "outputs": [],
   "source": [
    "def mutate(chrom: Chromosome, n_features: int):\n",
    "    \"\"\"\n",
    "    Quantile-aware, rule-aware mutation.\n",
    "    \"\"\"\n",
    "\n",
    "    for r in range(MAX_RULES):\n",
    "\n",
    "        # ---- mutate rule-level genes ----\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.rule_active[r] = 1 - chrom.rule_active[r]\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.side_gene[r] = 1 - chrom.side_gene[r]\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.tp_gene[r] = np.clip(\n",
    "                chrom.tp_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.001,\n",
    "                0.10,\n",
    "            )\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.sl_gene[r] = np.clip(\n",
    "                chrom.sl_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.001,\n",
    "                0.10,\n",
    "            )\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.size_gene[r] = np.clip(\n",
    "                chrom.size_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.05,\n",
    "                0.50,\n",
    "            )\n",
    "\n",
    "        # ---- mutate condition-level genes ----\n",
    "        for c in range(MAX_CONDS):\n",
    "\n",
    "            # only mutate conditions of active rules\n",
    "            if chrom.rule_active[r] == 0:\n",
    "                continue\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.cond_active[r, c] = 1 - chrom.cond_active[r, c]\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.feature_idx_gene[r, c] = np.random.randint(0, n_features)\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.operator_gene[r, c] = 1 - chrom.operator_gene[r, c]\n",
    "\n",
    "            # ⭐ Quantile mutation (replaces threshold_gene)\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.q_gene[r, c] = np.clip(\n",
    "                    chrom.q_gene[r, c] + np.random.normal(scale=0.08),\n",
    "                    0.05,\n",
    "                    0.95,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "9NzRZc4XVu-h"
   },
   "outputs": [],
   "source": [
    "# === 7. GA main loop ===\n",
    "\n",
    "def run_ga(df: pd.DataFrame,\n",
    "           feature_cols: List[str]\n",
    "           ) -> Tuple[Chromosome, float]:\n",
    "    \"\"\"\n",
    "    Run a simple GA to discover a good rule list.\n",
    "\n",
    "    Returns best_chromosome, best_fitness.\n",
    "    \"\"\"\n",
    "    n_features = len(feature_cols)\n",
    "\n",
    "    # --- Initialize population ---\n",
    "\n",
    "\n",
    "    initial_pop_size = POP_SIZE * 5\n",
    "    # population: List[Chromosome] = [\n",
    "    #     random_chromosome(n_features) for _ in range(initial_pop_size)\n",
    "    # ]\n",
    "    \n",
    "    \n",
    "    # use seed population instead of random population\n",
    "    population = seeded_population(df, feature_cols, initial_pop_size, seed_ratio=0.6)\n",
    "\n",
    "    # Evaluate initial population\n",
    "    fitnesses = [\n",
    "        compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "    ]\n",
    "\n",
    "    sorted_idx = np.argsort(fitnesses)[::-1]  # descending\n",
    "    population = [population[i] for i in sorted_idx[:POP_SIZE]]\n",
    "    fitnesses = [fitnesses[i] for i in sorted_idx[:POP_SIZE]]\n",
    "\n",
    "\n",
    "    best_idx = int(np.argmax(fitnesses))\n",
    "    best_chrom = population[best_idx]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "\n",
    "    print(f\"Initial best fitness (from expanded pool): {best_fit:.6f}\")\n",
    "\n",
    "\n",
    "    for gen in range(1, N_GENERATIONS + 1):\n",
    "        new_population: List[Chromosome] = []\n",
    "\n",
    "        # --- Elitism: keep the best individual ---\n",
    "        new_population.append(best_chrom)\n",
    "\n",
    "        # --- Generate rest of population ---\n",
    "        while len(new_population) < POP_SIZE:\n",
    "            # Select parents\n",
    "            p1 = tournament_selection(population, fitnesses)\n",
    "            p2 = tournament_selection(population, fitnesses)\n",
    "\n",
    "            # Crossover\n",
    "            child1, child2 = crossover(p1, p2)\n",
    "\n",
    "            # Mutation\n",
    "            mutate(child1, n_features)\n",
    "            mutate(child2, n_features)\n",
    "\n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < POP_SIZE:\n",
    "                new_population.append(child2)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [\n",
    "            compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "        ]\n",
    "\n",
    "        gen_best_idx = int(np.argmax(fitnesses))\n",
    "        gen_best_fit = fitnesses[gen_best_idx]\n",
    "\n",
    "        # Update global best\n",
    "        if gen_best_fit > best_fit:\n",
    "            best_fit = gen_best_fit\n",
    "            best_chrom = population[gen_best_idx]\n",
    "\n",
    "        print(f\"Generation {gen:3d}: best fitness = {gen_best_fit:.6f}, global best = {best_fit:.6f}\")\n",
    "\n",
    "    return best_chrom, best_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "MUZgrSmNVw8S"
   },
   "outputs": [],
   "source": [
    "def pretty_print_rules(rules, feature_cols):\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        cond_strs = []\n",
    "        for cond in rule.conditions:\n",
    "            feat_name = feature_cols[cond.feature_idx]\n",
    "\n",
    "            if cond.threshold is None:\n",
    "                cond_strs.append(\n",
    "                    f\"{feat_name} {cond.operator} q={cond.q:.2f}\"\n",
    "                )\n",
    "            else:\n",
    "                cond_strs.append(\n",
    "                    f\"{feat_name} {cond.operator} {cond.threshold:.4f}\"\n",
    "                )\n",
    "\n",
    "        cond_part = \" AND \".join(cond_strs)\n",
    "        print(f\"Rule {i}: IF {cond_part}\")\n",
    "        print(\n",
    "            f\"    THEN {rule.side} \"\n",
    "            f\"TP={rule.tp:.3f} SL={rule.sl:.3f} SIZE={rule.size_frac:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9E9EVODXHUE"
   },
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "uWwVnxrUQoau"
   },
   "outputs": [],
   "source": [
    "# Example usage (you adapt the paths and feature names):\n",
    "FEATURE_COLS = [\n",
    " \"cand_body_sign_5\",\n",
    " \"mom_cci_20\",\n",
    " \"vol_atr_14\",\n",
    " \"trend_lin_slope_50\",\n",
    " \"rob_zret_60\",\n",
    " \"rob_skew_30\",\n",
    " \"trend_dema_20\",\n",
    " \"vol_vwap_20\",\n",
    " \"cand_candle_dir_1\",\n",
    " \"vol_obv_1\",\n",
    " \"cand_gap_1\",\n",
    " \"trend_sma_5\",\n",
    " \"mom_chande_14\",\n",
    " \"vol_cmf_20\",\n",
    " \"vol_zclose_60\",\n",
    " \"vol_bbw_20_2\",\n",
    " \"vol_vroc_10\",\n",
    " \"mom_rsi_14\",\n",
    " \"structural_hh_hl_trend_score_50\",\n",
    " \"trendline_break_rsi_14\",\n",
    " \"mom_rsi_21\",\n",
    " \"vol_efficiency_ratio_30\",\n",
    " \"trend_pullback_strength_20\",\n",
    " \"spec_bandpower_low_20\",\n",
    " \"vol_kvo_norm_34_55\",\n",
    " \"vol_shock_energy_32\",\n",
    "]\n",
    "\n",
    "DoNotUse_FEATURE_COLS = [\n",
    "    \"pivot_dynamic_reversal_score_20\",\n",
    "    \"trend_tl_confluence\",\n",
    "    \"trend_trendlines_bear_cross_5_10\",\n",
    "    \"relative_strength_pair_20\",\n",
    "    \"calmar_ratio_50\",\n",
    "    \"beta_to_index_50\",\n",
    "    \"corr_with_index_50\",\n",
    "    \"inter_corr_eth_50\",\n",
    "    \"fear_greed_index_5m\",\n",
    "    \"inter_sp500_corr_50\",\n",
    "    \"inter_market_ratio_gold\",\n",
    "    \"sentiment_smooth_index\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Preprocessing Function ===\n",
    "\n",
    "def preprocess_trading_data(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    is_train: bool = True,\n",
    "    scaler_params: Optional[dict] = None\n",
    ") -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing for trading data with features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        List of feature column names to preprocess.\n",
    "    is_train : bool\n",
    "        If True, compute statistics from data. If False, use provided scaler_params.\n",
    "    scaler_params : dict, optional\n",
    "        Dictionary containing scaling parameters (mean, std, min, max, etc.) from training set.\n",
    "        Required when is_train=False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_processed : pd.DataFrame\n",
    "        Preprocessed DataFrame.\n",
    "    scaler_params : dict\n",
    "        Dictionary with scaling parameters for each feature (for use on test set).\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if scaler_params is None:\n",
    "        scaler_params = {}\n",
    "    \n",
    "    # 1. Handle infinite values (replace with NaN for proper handling)\n",
    "    print(f\"Processing {'TRAIN' if is_train else 'TEST'} data...\")\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # Replace inf/-inf with NaN\n",
    "            df_processed[col] = df_processed[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 2. Handle missing values\n",
    "    # Strategy: Forward fill first (use previous valid value), then backward fill, then fill remaining with median\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_missing_before = df_processed[col].isna().sum()\n",
    "            \n",
    "            if n_missing_before > 0:\n",
    "                # Forward fill (use last valid observation)\n",
    "                df_processed[col] = df_processed[col].ffill()\n",
    "                \n",
    "                # Backward fill for any remaining NaNs at the start\n",
    "                df_processed[col] = df_processed[col].bfill()\n",
    "                \n",
    "                # If still NaNs exist, fill with median (computed from train or stored)\n",
    "                if df_processed[col].isna().any():\n",
    "                    if is_train:\n",
    "                        median_val = df_processed[col].median()\n",
    "                        scaler_params[f\"{col}_median\"] = median_val\n",
    "                    else:\n",
    "                        median_val = scaler_params.get(f\"{col}_median\", 0.0)\n",
    "                    \n",
    "                    df_processed[col] = df_processed[col].fillna(median_val)\n",
    "                \n",
    "                n_missing_after = df_processed[col].isna().sum()\n",
    "                if n_missing_before > 0:\n",
    "                    print(f\"  {col}: filled {n_missing_before} missing values -> {n_missing_after} remaining\")\n",
    "    \n",
    "    # 3. Remove outliers (clip to reasonable ranges based on percentiles)\n",
    "    # This prevents extreme values from distorting the strategy\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "                continue\n",
    "\n",
    "        # ⚠️ Boolean هم numeric محسوب می‌شود، پس حذفش کن\n",
    "            if pd.api.types.is_bool_dtype(df_processed[col]):\n",
    "                continue\n",
    "\n",
    "            if is_train:\n",
    "                # Compute 1st and 99th percentiles\n",
    "                lower_bound = df_processed[col].quantile(0.01)\n",
    "                upper_bound = df_processed[col].quantile(0.99)\n",
    "                scaler_params[f\"{col}_lower\"] = lower_bound\n",
    "                scaler_params[f\"{col}_upper\"] = upper_bound\n",
    "            else:\n",
    "                lower_bound = scaler_params.get(f\"{col}_lower\", df_processed[col].min())\n",
    "                upper_bound = scaler_params.get(f\"{col}_upper\", df_processed[col].max())\n",
    "            \n",
    "            # Clip values\n",
    "            df_processed[col] = df_processed[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    # 4. Standardization (Z-score normalization)\n",
    "    # This ensures all features have similar scales for threshold mapping\n",
    "    # 4. Standardization (Z-score normalization)\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "\n",
    "            if not pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "                continue\n",
    "            if pd.api.types.is_bool_dtype(df_processed[col]):\n",
    "                continue\n",
    "\n",
    "            if is_train:\n",
    "                mean_val = df_processed[col].mean()\n",
    "                std_val = df_processed[col].std()\n",
    "                if std_val == 0 or np.isnan(std_val):\n",
    "                    std_val = 1.0\n",
    "                scaler_params[f\"{col}_mean\"] = mean_val\n",
    "                scaler_params[f\"{col}_std\"] = std_val\n",
    "            else:\n",
    "                mean_val = scaler_params.get(f\"{col}_mean\", 0.0)\n",
    "                std_val = scaler_params.get(f\"{col}_std\", 1.0)\n",
    "        df_processed[col] = (df_processed[col] - mean_val) / std_val\n",
    "\n",
    "    # 5. Final check: ensure no NaNs or infs remain\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_invalid = df_processed[col].isna().sum() + np.isinf(df_processed[col]).sum()\n",
    "            if n_invalid > 0:\n",
    "                print(f\"  WARNING: {col} still has {n_invalid} invalid values after preprocessing!\")\n",
    "                # Final fallback: fill with 0\n",
    "                df_processed[col] = df_processed[col].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Shape: {df_processed.shape}\")\n",
    "    print(f\"Date range: {df_processed.index[0]} to {df_processed.index[-1]}\")\n",
    "    print(f\"Number of features: {len(feature_cols)}\")\n",
    "    \n",
    "    return df_processed, scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "oo9cKOi0RZi6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train data shape: (52992, 27)\n",
      "Raw test data shape: (26208, 27)\n",
      "Processing TRAIN data...\n",
      "  vol_shock_energy_32: filled 33 missing values -> 0 remaining\n",
      "  trend_pullback_strength_20: filled 19 missing values -> 0 remaining\n",
      "  rob_skew_30: filled 29 missing values -> 0 remaining\n",
      "  trend_sma_5: filled 4 missing values -> 0 remaining\n",
      "  cand_body_sign_5: filled 4 missing values -> 0 remaining\n",
      "  vol_efficiency_ratio_30: filled 30 missing values -> 0 remaining\n",
      "  trend_lin_slope_50: filled 49 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  vol_kvo_norm_34_55: filled 54 missing values -> 0 remaining\n",
      "  spec_bandpower_low_20: filled 24 missing values -> 0 remaining\n",
      "  vol_vwap_20: filled 19 missing values -> 0 remaining\n",
      "  mom_rsi_21: filled 21 missing values -> 0 remaining\n",
      "  cand_gap_1: filled 1 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  mom_cci_20: filled 19 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 40 missing values -> 0 remaining\n",
      "  rob_zret_60: filled 60 missing values -> 0 remaining\n",
      "  mom_chande_14: filled 14 missing values -> 0 remaining\n",
      "  vol_atr_14: filled 13 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (52992, 27)\n",
      "Date range: 2025-03-01 00:00:00 to 2025-08-31 23:55:00\n",
      "Number of features: 26\n",
      "Processing TEST data...\n",
      "  vol_shock_energy_32: filled 33 missing values -> 0 remaining\n",
      "  trend_pullback_strength_20: filled 19 missing values -> 0 remaining\n",
      "  rob_skew_30: filled 29 missing values -> 0 remaining\n",
      "  trend_sma_5: filled 4 missing values -> 0 remaining\n",
      "  cand_body_sign_5: filled 4 missing values -> 0 remaining\n",
      "  vol_efficiency_ratio_30: filled 30 missing values -> 0 remaining\n",
      "  trend_lin_slope_50: filled 49 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  vol_kvo_norm_34_55: filled 54 missing values -> 0 remaining\n",
      "  spec_bandpower_low_20: filled 24 missing values -> 0 remaining\n",
      "  vol_vwap_20: filled 19 missing values -> 0 remaining\n",
      "  mom_rsi_21: filled 21 missing values -> 0 remaining\n",
      "  cand_gap_1: filled 1 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  mom_cci_20: filled 19 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 19 missing values -> 0 remaining\n",
      "  rob_zret_60: filled 60 missing values -> 0 remaining\n",
      "  mom_chande_14: filled 14 missing values -> 0 remaining\n",
      "  vol_atr_14: filled 13 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (26208, 27)\n",
      "Date range: 2025-09-01 00:00:00 to 2025-11-30 23:55:00\n",
      "Number of features: 26\n",
      "\n",
      "Final train data shape: (52992, 27)\n",
      "Final test data shape: (26208, 27)\n"
     ]
    }
   ],
   "source": [
    "df, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "df_test, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features_test.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "\n",
    "print(f\"Raw train data shape: {df.shape}\")\n",
    "print(f\"Raw test data shape: {df_test.shape}\")\n",
    "\n",
    "# Apply preprocessing\n",
    "df, scaler_params = preprocess_trading_data(df, FEATURE_COLS, is_train=True)\n",
    "df_test, _ = preprocess_trading_data(df_test, FEATURE_COLS, is_train=False, scaler_params=scaler_params)\n",
    "\n",
    "print(f\"\\nFinal train data shape: {df.shape}\")\n",
    "print(f\"Final test data shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsxYy-lfVz9-",
    "outputId": "b8aefcf5-a675-49b3-d11b-ca7fe3b7ac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best fitness (from expanded pool): 1165.911888\n",
      "Generation   1: best fitness = 1165.911888, global best = 1165.911888\n",
      "Generation   2: best fitness = 1165.911888, global best = 1165.911888\n",
      "Generation   3: best fitness = 1165.911888, global best = 1165.911888\n",
      "Generation   4: best fitness = 1165.911888, global best = 1165.911888\n",
      "Generation   5: best fitness = 1165.911888, global best = 1165.911888\n",
      "Generation   6: best fitness = 1166.523107, global best = 1166.523107\n",
      "Generation   7: best fitness = 1171.437939, global best = 1171.437939\n",
      "Generation   8: best fitness = 1171.437939, global best = 1171.437939\n",
      "Generation   9: best fitness = 1171.437939, global best = 1171.437939\n",
      "Generation  10: best fitness = 1171.437939, global best = 1171.437939\n",
      "\n",
      "Best fitness found: 1171.437939\n",
      "Rule 1: IF trend_sma_5 < -0.8891\n",
      "    THEN BUY TP=0.032 SL=0.076 SIZE=0.39\n",
      "Rule 2: IF vol_atr_14 > 0.6206\n",
      "    THEN BUY TP=0.024 SL=0.062 SIZE=0.37\n",
      "Train final equity: 1295.63, Number of positions: 139\n",
      "Test  final equity: 938.81, Number of positions: 73\n",
      "Best rules exported to rules_G09.json\n"
     ]
    }
   ],
   "source": [
    "# 1) Run GA\n",
    "best_chrom, best_fit = run_ga(df, FEATURE_COLS)\n",
    "print(f\"\\nBest fitness found: {best_fit:.6f}\")\n",
    "\n",
    "# 2) Decode and show final rule list\n",
    "best_rules = decode_chromosome(best_chrom, df, FEATURE_COLS)\n",
    "compute_condition_thresholds(best_rules, df, FEATURE_COLS)\n",
    "\n",
    "pretty_print_rules(best_rules, FEATURE_COLS)\n",
    "\n",
    "# 3) Evaluate on TRAIN and TEST (3-month out-of-sample)\n",
    "train_equity_curve, final_train_eq, n_train_trades = backtest_rule_list(\n",
    "    best_rules, df, FEATURE_COLS\n",
    ")\n",
    "\n",
    "test_equity_curve, final_test_eq, n_test_trades = backtest_rule_list(\n",
    "    best_rules, df_test, FEATURE_COLS\n",
    ")\n",
    "\n",
    "print(f\"Train final equity: {final_train_eq:.2f}, Number of positions: {n_train_trades}\")\n",
    "print(f\"Test  final equity: {final_test_eq:.2f}, Number of positions: {n_test_trades}\")\n",
    "\n",
    "# 4) Export best rules to JSON (schema-compliant)\n",
    "rules_json = {\"rules\": []}\n",
    "\n",
    "for rule in best_rules:\n",
    "    rule_dict = {\"conditions\": [], \"action\": {}}\n",
    "\n",
    "    for cond in rule.conditions:\n",
    "        feat_name = FEATURE_COLS[cond.feature_idx]\n",
    "        rule_dict[\"conditions\"].append({\n",
    "            \"feature\": feat_name,\n",
    "            \"op\": cond.operator,\n",
    "            \"threshold\": cond.threshold\n",
    "        })\n",
    "\n",
    "    rule_dict[\"action\"] = {\n",
    "        \"side\": rule.side,\n",
    "        \"tp\": rule.tp,\n",
    "        \"sl\": rule.sl,\n",
    "        \"size\": rule.size_frac\n",
    "    }\n",
    "\n",
    "    rules_json[\"rules\"].append(rule_dict)\n",
    "\n",
    "with open(\"rules_G09.json\", \"w\") as f:\n",
    "    json.dump(rules_json, f, indent=4)\n",
    "\n",
    "print(\"Best rules exported to rules_G09.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rules from JSON:\n",
      "Rule 1: IF trend_sma_5 < -0.8891\n",
      "    THEN BUY TP=0.032 SL=0.076 SIZE=0.39\n",
      "Rule 2: IF vol_atr_14 > 0.6206\n",
      "    THEN BUY TP=0.024 SL=0.062 SIZE=0.37\n",
      "\n",
      "Train final equity: 1295.63, Number of positions: 139\n",
      "Test  final equity: 938.81, Number of positions: 73\n"
     ]
    }
   ],
   "source": [
    "# --- Load rules from JSON and evaluate on train/test\n",
    "import os, json\n",
    "\n",
    "\n",
    "def load_rules_from_json(json_path: str, feature_cols: List[str]) -> List[Rule]:\n",
    "    \"\"\"Load rules from a JSON file and convert to `Rule` objects.\"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f'JSON file not found: {json_path}')\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rules_out: List[Rule] = []\n",
    "    for r in data.get('rules', []):\n",
    "        conds: List[Condition] = []\n",
    "        for c in r.get('conditions', []):\n",
    "            feat_name = c.get('feature')\n",
    "            # try to match feature name (case-insensitive) to provided feature_cols\n",
    "            feat_idx = None\n",
    "            if feat_name in feature_cols:\n",
    "                feat_idx = feature_cols.index(feat_name)\n",
    "            else:\n",
    "                # try lower-case match\n",
    "                try:\n",
    "                    feat_idx = feature_cols.index(feat_name.lower())\n",
    "                except Exception:\n",
    "                    feat_idx = None\n",
    "\n",
    "            if feat_idx is None:\n",
    "                print(f'Warning: feature \"{feat_name}\" not found in FEATURE_COLS — skipping condition')\n",
    "                continue\n",
    "\n",
    "            op = c.get('op', '>')\n",
    "            thr = c.get('threshold', None)\n",
    "            # use a neutral q (quantile) when JSON gives absolute threshold\n",
    "            q = 0.5\n",
    "            conds.append(Condition(feature_idx=feat_idx, operator=op, q=q, threshold=thr))\n",
    "\n",
    "        action = r.get('action', {})\n",
    "        side = action.get('side', 'BUY')\n",
    "        tp = action.get('tp', TP_MIN)\n",
    "        sl = action.get('sl', SL_MIN)\n",
    "        size = action.get('size', POS_MIN_FRAC)\n",
    "\n",
    "        if len(conds) == 0:\n",
    "            # skip empty rule\n",
    "            continue\n",
    "\n",
    "        rules_out.append(Rule(conditions=conds, side=side, tp=tp, sl=sl, size_frac=size))\n",
    "\n",
    "    return rules_out\n",
    "\n",
    "\n",
    "def compute_condition_thresholds_if_missing(rules, df_reference: pd.DataFrame, feature_cols):\n",
    "    \"\"\"Compute thresholds from quantiles only when `threshold` is missing.\"\"\"\n",
    "    for r in rules:\n",
    "        for cond in r.conditions:\n",
    "            if getattr(cond, 'threshold', None) is not None:\n",
    "                # do not overwrite an explicit numeric threshold from JSON\n",
    "                continue\n",
    "\n",
    "            feat = feature_cols[cond.feature_idx]\n",
    "            series = df_reference[feat].dropna()\n",
    "            if len(series) == 0:\n",
    "                cond.threshold = None\n",
    "                continue\n",
    "            q = min(max(cond.q, 0.01), 0.99)\n",
    "            cond.threshold = float(series.quantile(q))\n",
    "\n",
    "\n",
    "# -- Usage: load rules and test --\n",
    "json_path = 'rules_G09.json'\n",
    "loaded_rules = load_rules_from_json(json_path, FEATURE_COLS)\n",
    "# compute thresholds only where missing (prevents overwriting absolute thresholds)\n",
    "compute_condition_thresholds_if_missing(loaded_rules, df, FEATURE_COLS)\n",
    "\n",
    "print('Loaded rules from JSON:')\n",
    "pretty_print_rules(loaded_rules, FEATURE_COLS)\n",
    "\n",
    "# Evaluate on TRAIN and TEST\n",
    "train_equity_curve, final_train_eq, n_train_trades = backtest_rule_list(loaded_rules, df, FEATURE_COLS)\n",
    "test_equity_curve, final_test_eq, n_test_trades = backtest_rule_list(loaded_rules, df_test, FEATURE_COLS)\n",
    "\n",
    "print(f\"\\nTrain final equity: {final_train_eq:.2f}, Number of positions: {n_train_trades}\")\n",
    "print(f\"Test  final equity: {final_test_eq:.2f}, Number of positions: {n_test_trades}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
