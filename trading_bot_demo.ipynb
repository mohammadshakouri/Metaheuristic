{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook Overview: Rule-Based Trading with Metaheuristic Rule Discovery**\n",
    "\n",
    "This notebook presents a complete demonstration of a **rule-based trading system** applied to Ethereum price data. The objective is to illustrate how **Genetic Algorithms (GA)** can be used to *automatically discover interpretable IF–THEN trading rules* based on engineered features from **Phase 1 of the course** .\n",
    "\n",
    "The implementation follows the conceptual framework introduced in the accompanying lecture materials on **Rule Discovery with Metaheuristics** .\n",
    "\n",
    "---\n",
    "\n",
    "## **Purpose of the Notebook**\n",
    "\n",
    "The notebook serves as a educational example demonstrating:\n",
    "\n",
    "1. **How trading rules are encoded as chromosomes** within a GA.\n",
    "2. **How conditions, actions, TP/SL levels, and position sizing are represented genetically.**\n",
    "3. **How a rule list is decoded and executed via a backtesting engine.**\n",
    "4. **How the GA iteratively improves candidate rule sets** using fitness feedback from historical performance.\n",
    "\n",
    "Although the demonstration uses only a subset of features, students may extend the system to incorporate the full set of engineered indicators produced in Phase 1.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chromosome Structure and Representation**\n",
    "\n",
    "Each chromosome represents a **complete ordered rule list**, where:\n",
    "\n",
    "* Each rule consists of multiple **conditions**, specifying a feature, operator, and threshold.\n",
    "* Each rule also encodes its **action parameters**:\n",
    "\n",
    "  * Take-profit (TP),\n",
    "  * Stop-loss (SL),\n",
    "  * **Fraction of capital allocated to the trade** (position size).\n",
    "* Activation flags control whether a rule or condition is included in the effective strategy.\n",
    "\n",
    "The genetic representation enables exploration of a very large combinational search space while retaining **transparent, human-readable rule structures** once decoded.\n",
    "\n",
    "---\n",
    "\n",
    "## **Training Data and Features**\n",
    "\n",
    "For this demonstration, we use only a small set of the available features to keep the example focused and computationally manageable.\n",
    "However, students are encouraged to:\n",
    "\n",
    "* Use **all available engineered features**,\n",
    "* Modify or extend the chromosome structure,\n",
    "* Experiment with different operator sets, thresholds, or rule depths.\n",
    "\n",
    "The system is fully modular, and feature selection is handled implicitly via the genetic encoding.\n",
    "\n",
    "---\n",
    "\n",
    "## **Optimization and Fitness Function**\n",
    "\n",
    "The GA is trained exclusively on the **training dataset**.\n",
    "The objective function (fitness) is defined as:\n",
    "\n",
    "> **Final equity obtained after backtesting the rule set**, starting with an initial capital of $1000.\n",
    "\n",
    "This formulation incorporates:\n",
    "\n",
    "* Profitability of trades,\n",
    "* Trading frequency,\n",
    "* Position sizing decisions,\n",
    "* Compounding through equity updates.\n",
    "\n",
    "After training, students must evaluate their discovered rule sets on the **separate test dataset** to assess out-of-sample performance and detect overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Student Instructions**\n",
    "\n",
    "* You may run this notebook directly in **Google Colab**, but remember to mount your Google Drive before accessing datasets.\n",
    "* All configuration parameters (e.g., population size, mutation rates, TP/SL ranges, position-size bounds) can be modified to explore different design choices.\n",
    "* The implementation is modular; students may:\n",
    "\n",
    "  * Add new features,\n",
    "  * Adjust how rules are represented,\n",
    "  * Implement alternative fitness functions,\n",
    "  * Replace GA with other metaheuristic algorithms such as PSO or DE.\n",
    "\n",
    "---\n",
    "\n",
    "## **Educational Goals**\n",
    "\n",
    "By working through this notebook, you will gain hands-on understanding of:\n",
    "\n",
    "* How rule-based trading systems are formalized and optimized,\n",
    "* How metaheuristic methods operate on structured, interpretable solutions,\n",
    "* How backtesting interacts with rule logic, signal generation, and position management,\n",
    "* How to evaluate trading strategies rigorously using both train and test datasets.\n",
    "\n",
    "This forms the foundation for the **Phase 2 Rule Discovery Project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwFOr1myb2ie",
    "outputId": "6fe2ad62-bf85-4b9f-cd5a-a28ce937d1ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DGriP3ayPLD_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xqnmtLloQizq"
   },
   "outputs": [],
   "source": [
    "# === CONFIG: rule structure, GA, and trading ===\n",
    "\n",
    "MAX_RULES = 4         # N (max rules in the rule list)\n",
    "MAX_CONDS = 2          # K (max conditions per rule)\n",
    "\n",
    "TP_MIN, TP_MAX = 0.02, 0.05   # 2% .. 5%\n",
    "SL_MIN, SL_MAX = 0.01, 0.04   # 1% .. 4%\n",
    "\n",
    "STARTING_CAPITAL = 1000.0    # starting money for the strategy\n",
    "\n",
    "POS_MIN_FRAC = 0.05          # 10% of capital per trade (min)\n",
    "POS_MAX_FRAC = 0.30          # 50% of capital per trade (max)\n",
    "\n",
    "POP_SIZE = 6\n",
    "N_GENERATIONS = 40\n",
    "TOURNAMENT_SIZE = 5\n",
    "CROSSOVER_RATE = 0.85\n",
    "MUTATION_RATE = 0.08   # base mutation probability per gene\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0509KhbyQmMA"
   },
   "outputs": [],
   "source": [
    "# === 1. Load ETH data with engineered features ===\n",
    "\n",
    "def load_eth_features(csv_path: str,\n",
    "                      feature_cols: List[str],\n",
    "                      close_col: str = \"close\"\n",
    "                      ) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load ETH OHLCV + engineered features.\n",
    "    We keep only 'close' and selected feature columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV containing at least 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        Subset of ~50 features you want to use in the demo.\n",
    "    close_col : str\n",
    "        Name of the close price column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame indexed by time with 'close' and selected features.\n",
    "    feature_cols_used : list of str\n",
    "        The actual feature columns we keep (intersection of requested + available).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=True, index_col=0)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    if close_col.lower() not in df.columns:\n",
    "        raise ValueError(f\"Close column '{close_col}' not found in data.\")\n",
    "\n",
    "    # Intersect requested features with available columns\n",
    "    feature_cols_lower = [c.lower() for c in feature_cols]\n",
    "    available_features = [c for c in feature_cols_lower if c in df.columns]\n",
    "\n",
    "    if len(available_features) == 0:\n",
    "        raise ValueError(\"None of the requested feature columns are present in the data.\")\n",
    "\n",
    "    cols_to_keep = [close_col.lower()] + available_features\n",
    "    df = df[cols_to_keep].sort_index()\n",
    "\n",
    "    return df, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J0q2R-qiS3e8"
   },
   "outputs": [],
   "source": [
    "# === 2. Gene and Rule structures (phenotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Condition:\n",
    "    # active: bool\n",
    "    feature_idx: int\n",
    "    operator: str      # \"<\" or \">\"\n",
    "    q: float    # ADD FOR QUANTILE\n",
    "    threshold: float = None   # numeric threshold\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rule:\n",
    "    # active: bool\n",
    "    conditions: List[Condition]\n",
    "    side: str          # \"BUY\" or \"SELL\"\n",
    "    tp: float          # take-profit as decimal (e.g. 0.03 for 3%)\n",
    "    sl: float          # stop-loss as decimal\n",
    "    size_frac: float   # fraction of current capital to allocate (0.0–1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3bN_E5mZTHEg"
   },
   "outputs": [],
   "source": [
    "# === 2b. Chromosome representation (genotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Chromosome:\n",
    "    # Rule-level genes\n",
    "    rule_active: np.ndarray      # (MAX_RULES,)  {0,1}\n",
    "    side_gene: np.ndarray        # (MAX_RULES,)  {0,1}  0=BUY, 1=SELL\n",
    "    tp_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    sl_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    size_gene: np.ndarray        # (MAX_RULES,)  [0,1]  --> position size fraction\n",
    "\n",
    "    # Condition-level genes\n",
    "    cond_active: np.ndarray      # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    feature_idx_gene: np.ndarray # (MAX_RULES, MAX_CONDS)\n",
    "    operator_gene: np.ndarray    # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    # threshold_gene: np.ndarray   # (MAX_RULES, MAX_CONDS)  [0,1]\n",
    "    q_gene: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-VRFr0mrTMJI"
   },
   "outputs": [],
   "source": [
    "# === 3. Mapping genes to actual TP/SL and thresholds ===\n",
    "\n",
    "def map_tp_gene(tp_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to TP% in [TP_MIN, TP_MAX].\"\"\"\n",
    "    return TP_MIN + tp_gene * (TP_MAX - TP_MIN)\n",
    "\n",
    "\n",
    "def map_sl_gene(sl_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to SL% in [SL_MIN, SL_MAX].\"\"\"\n",
    "    return SL_MIN + sl_gene * (SL_MAX - SL_MIN)\n",
    "\n",
    "\n",
    "def map_size_gene(size_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map [0,1] size_gene to a fraction of capital to allocate per trade.\n",
    "    For example, POS_MIN_FRAC=0.05, POS_MAX_FRAC=0.5 => 5%..50%.\n",
    "    \"\"\"\n",
    "    return POS_MIN_FRAC + size_gene * (POS_MAX_FRAC - POS_MIN_FRAC)\n",
    "\n",
    "\n",
    "def map_operator_gene(op_gene: int) -> str:\n",
    "    \"\"\"0 -> '<', 1 -> '>'.\"\"\"\n",
    "    return \"<\" if op_gene == 0 else \">\"\n",
    "\n",
    "\n",
    "def map_threshold_gene_to_value(feature_series: pd.Series, thr_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map a [0,1] threshold_gene to a numeric threshold using feature quantiles.\n",
    "\n",
    "    thr_gene ~ 0.0 => low quantile (e.g. oversold RSI)\n",
    "    thr_gene ~ 1.0 => high quantile (e.g. overbought RSI)\n",
    "    \"\"\"\n",
    "    # np.nanquantile handles NaNs gracefully\n",
    "    return float(np.nanquantile(feature_series.values, thr_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_condition_thresholds(\n",
    "    rules,\n",
    "    df_reference: pd.DataFrame,\n",
    "    feature_cols\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute real thresholds using quantiles from df_reference only.\n",
    "    Prevents data leakage.\n",
    "    \"\"\"\n",
    "    for r in rules:\n",
    "        for cond in r.conditions:\n",
    "            feat = feature_cols[cond.feature_idx]\n",
    "            series = df_reference[feat].dropna()\n",
    "\n",
    "            if len(series) == 0:\n",
    "                cond.threshold = None\n",
    "                continue\n",
    "\n",
    "            q = min(max(cond.q, 0.01), 0.99)\n",
    "            cond.threshold = float(series.quantile(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b6hGCuyETa8e"
   },
   "outputs": [],
   "source": [
    "# === Decode Chromosome to Rule List (Quantile-based) ===\n",
    "\n",
    "def decode_chromosome(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> List[Rule]:\n",
    "    \"\"\"\n",
    "    Decode chromosome into a list of Rule objects.\n",
    "    IMPORTANT:\n",
    "    - This function does NOT compute numeric thresholds.\n",
    "    - It only assigns quantile genes (q).\n",
    "    - Real thresholds are computed later using compute_condition_thresholds().\n",
    "    \"\"\"\n",
    "\n",
    "    rules: List[Rule] = []\n",
    "\n",
    "    for r in range(MAX_RULES):\n",
    "        if chrom.rule_active[r] == 0:\n",
    "            continue\n",
    "\n",
    "        # --- rule-level genes ---\n",
    "        side = \"BUY\" if chrom.side_gene[r] == 0 else \"SELL\"\n",
    "        tp = map_tp_gene(chrom.tp_gene[r])\n",
    "        sl = map_sl_gene(chrom.sl_gene[r])\n",
    "        size_frac = map_size_gene(chrom.size_gene[r])\n",
    "\n",
    "        conds: List[Condition] = []\n",
    "\n",
    "        for c in range(MAX_CONDS):\n",
    "            if chrom.cond_active[r, c] == 0:\n",
    "                continue\n",
    "\n",
    "            feat_idx = int(chrom.feature_idx_gene[r, c]) % len(feature_cols)\n",
    "            op = map_operator_gene(int(chrom.operator_gene[r, c]))\n",
    "\n",
    "            # ⭐ Quantile gene (NOT numeric threshold)\n",
    "            q = float(chrom.q_gene[r, c])   # اگر اسم را عوض نکردی: threshold_gene\n",
    "\n",
    "            conds.append(\n",
    "                Condition(\n",
    "                    feature_idx=feat_idx,\n",
    "                    operator=op,\n",
    "                    q=q,              # quantile ∈ (0,1)\n",
    "                    threshold=None    # computed later\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # discard empty rules\n",
    "        if len(conds) == 0:\n",
    "            continue\n",
    "\n",
    "        rules.append(\n",
    "            Rule(\n",
    "                conditions=conds,\n",
    "                side=side,\n",
    "                tp=tp,\n",
    "                sl=sl,\n",
    "                size_frac=size_frac,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5CoyXYyWTxAQ"
   },
   "outputs": [],
   "source": [
    "def rule_fires(\n",
    "    rule: Rule,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    t: int\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if a rule fires at row index t.\n",
    "    All conditions must be true.\n",
    "\n",
    "    Quantile-based note:\n",
    "    - cond.threshold MUST be pre-computed (e.g., by compute_condition_thresholds).\n",
    "    - If threshold is None, rule does not fire (prevents leakage / undefined behavior).\n",
    "    \"\"\"\n",
    "    row = df.iloc[t]\n",
    "\n",
    "    for cond in rule.conditions:\n",
    "        # threshold must exist\n",
    "        thr = getattr(cond, \"threshold\", None)\n",
    "        if thr is None or np.isnan(thr):\n",
    "            return False\n",
    "\n",
    "        feat_name = feature_cols[cond.feature_idx]\n",
    "        x = row[feat_name]\n",
    "\n",
    "        # missing feature => don't fire\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return False\n",
    "\n",
    "        op = cond.operator\n",
    "        if op == \"<\":\n",
    "            if not (x < thr):\n",
    "                return False\n",
    "        elif op == \">\":\n",
    "            if not (x > thr):\n",
    "                return False\n",
    "        else:\n",
    "            # unknown operator => safe fail\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oPAdngejVHJ1"
   },
   "outputs": [],
   "source": [
    "# def backtest_rule_list(\n",
    "#     rules: List[Rule],\n",
    "#     df: pd.DataFrame,\n",
    "#     feature_cols: List[str],\n",
    "#     starting_capital: float = STARTING_CAPITAL\n",
    "# ) -> Tuple[List[float], float]:\n",
    "#     \"\"\"\n",
    "#     Backtest a rule list with capital and position sizing.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     trade_returns : list of float\n",
    "#         Per-trade returns (in % terms, like before).\n",
    "#     final_equity : float\n",
    "#         Final money after all trades.\n",
    "#     \"\"\"\n",
    "#     if len(rules) == 0:\n",
    "#         return [], starting_capital\n",
    "\n",
    "#     close = df[\"close\"].values\n",
    "#     n = len(df)\n",
    "\n",
    "#     equity = starting_capital\n",
    "\n",
    "#     position = 0          # 0 = flat, +1 = long, -1 = short\n",
    "#     entry_price = None\n",
    "#     entry_rule: Optional[Rule] = None\n",
    "#     entry_capital = None  # amount of capital allocated to this trade\n",
    "\n",
    "#     trade_returns: List[float] = []\n",
    "\n",
    "#     for t in range(n):\n",
    "#         price = close[t]\n",
    "#         if np.isnan(price):\n",
    "#             continue\n",
    "\n",
    "#         if position == 0:\n",
    "#             # --- FLAT: look for entry ---\n",
    "#             for rule in rules:\n",
    "#                 if rule_fires(rule, df, feature_cols, t):\n",
    "#                     # Capital to allocate = fraction of current equity\n",
    "#                     size_frac = rule.size_frac\n",
    "#                     trade_capital = equity * size_frac\n",
    "\n",
    "#                     if trade_capital <= 0:\n",
    "#                         break  # nothing to allocate\n",
    "\n",
    "#                     position = 1 if rule.side == \"BUY\" else -1\n",
    "#                     entry_price = price\n",
    "#                     entry_rule = rule\n",
    "#                     entry_capital = trade_capital\n",
    "#                     break\n",
    "\n",
    "#         else:\n",
    "#             # --- IN POSITION: manage trade ---\n",
    "#             assert entry_rule is not None and entry_price is not None and entry_capital is not None\n",
    "\n",
    "#             # Return in direction of position (+ for profit)\n",
    "#             ret = position * (price / entry_price - 1.0)\n",
    "\n",
    "#             tp_hit = ret >= entry_rule.tp\n",
    "#             sl_hit = ret <= -entry_rule.sl\n",
    "\n",
    "#             if tp_hit or sl_hit:\n",
    "#                 # Close trade\n",
    "#                 pnl = ret * entry_capital      # profit or loss in dollars\n",
    "#                 equity += pnl                  # update money\n",
    "#                 trade_returns.append(ret)\n",
    "\n",
    "#                 # Reset position\n",
    "#                 position = 0\n",
    "#                 entry_price = None\n",
    "#                 entry_rule = None\n",
    "#                 entry_capital = None\n",
    "\n",
    "#     return trade_returns, equity\n",
    "\n",
    "def backtest_rule_list(\n",
    "    rules: List[Rule],\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    starting_capital: float = STARTING_CAPITAL\n",
    ") -> Tuple[List[float], float, int]:\n",
    "    \"\"\"\n",
    "    Backtest a rule list with capital and position sizing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    equity_curve : list of float\n",
    "        True equity over time (incremental)\n",
    "    final_equity : float\n",
    "        Final money after all trades\n",
    "    n_trades : int\n",
    "        Number of closed trades\n",
    "    \"\"\"\n",
    "    if len(rules) == 0:\n",
    "        return [starting_capital], starting_capital, 0\n",
    "\n",
    "    close = df[\"close\"].values\n",
    "    n = len(df)\n",
    "\n",
    "    equity = float(starting_capital)\n",
    "    equity_curve = [equity]\n",
    "\n",
    "    position = 0          # 0 = flat, +1 = long, -1 = short\n",
    "    entry_price = None\n",
    "    entry_rule: Optional[Rule] = None\n",
    "    entry_capital = None\n",
    "\n",
    "    n_trades = 0\n",
    "\n",
    "    for t in range(n):\n",
    "        price = close[t]\n",
    "        if np.isnan(price):\n",
    "            equity_curve.append(equity)\n",
    "            continue\n",
    "\n",
    "        if position == 0:\n",
    "            # --- FLAT: look for entry ---\n",
    "            for rule in rules:\n",
    "                if rule_fires(rule, df, feature_cols, t):\n",
    "                    size_frac = rule.size_frac\n",
    "                    trade_capital = equity * size_frac\n",
    "\n",
    "                    if trade_capital <= 0:\n",
    "                        break\n",
    "\n",
    "                    position = 1 if rule.side == \"BUY\" else -1\n",
    "                    entry_price = price\n",
    "                    entry_rule = rule\n",
    "                    entry_capital = trade_capital\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            # --- IN POSITION: manage trade ---\n",
    "            ret = position * (price / entry_price - 1.0)\n",
    "\n",
    "            tp_hit = ret >= entry_rule.tp\n",
    "            sl_hit = ret <= -entry_rule.sl\n",
    "\n",
    "            if tp_hit or sl_hit:\n",
    "                pnl = ret * entry_capital\n",
    "                equity += pnl\n",
    "\n",
    "                position = 0\n",
    "                entry_price = None\n",
    "                entry_rule = None\n",
    "                entry_capital = None\n",
    "\n",
    "                n_trades += 1\n",
    "\n",
    "        equity_curve.append(equity)\n",
    "\n",
    "    # --- force close at last price (important!) ---\n",
    "    if position != 0 and entry_price is not None and entry_capital is not None:\n",
    "        final_price = close[-1]\n",
    "        if not np.isnan(final_price):\n",
    "            ret = position * (final_price / entry_price - 1.0)\n",
    "            pnl = ret * entry_capital\n",
    "            equity += pnl\n",
    "            equity_curve[-1] = equity\n",
    "            n_trades += 1\n",
    "\n",
    "    return equity_curve, equity, n_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-YF-8MCYVase"
   },
   "outputs": [],
   "source": [
    "# def compute_fitness(\n",
    "#     chrom: Chromosome,\n",
    "#     df: pd.DataFrame,\n",
    "#     feature_cols: List[str]\n",
    "# ) -> float:\n",
    "#     \"\"\"\n",
    "#     Decode chromosome -> rule list -> backtest -> final equity.\n",
    "\n",
    "#     Fitness = final money (higher is better).\n",
    "#     \"\"\"\n",
    "#     rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "#     trade_returns, final_equity = backtest_rule_list(\n",
    "#         rules, df, feature_cols, starting_capital=STARTING_CAPITAL\n",
    "#     )\n",
    "\n",
    "#     # Optional: if you want to slightly penalize \"do nothing\" strategies:\n",
    "#     if len(trade_returns) == 0:\n",
    "#         return STARTING_CAPITAL - 1.0  # tiny penalty\n",
    "\n",
    "#     return final_equity\n",
    "\n",
    "def compute_fitness(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Walk-forward + Quantile-based fitness.\n",
    "    Robust against overfitting and scale drift.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Decode chromosome → rules (WITHOUT numeric thresholds)\n",
    "    rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "    # 2) Walk-forward split\n",
    "    n = len(df)\n",
    "    if n < 100:  # safety guard\n",
    "        return -1e6\n",
    "\n",
    "    split = int(0.7 * n)\n",
    "    df_A = df.iloc[:split]\n",
    "    df_B = df.iloc[split:]\n",
    "\n",
    "    # 3) ⭐ Compute REAL thresholds from df_A ONLY (quantile-based)\n",
    "    compute_condition_thresholds(rules, df_A, feature_cols)\n",
    "\n",
    "    # 4) Backtest on A (train part)\n",
    "    eq_A_curve, final_A, trades_A = backtest_rule_list(\n",
    "        rules, df_A, feature_cols\n",
    "    )\n",
    "\n",
    "    # 5) Backtest on B (forward / pseudo-test)\n",
    "    eq_B_curve, final_B, trades_B = backtest_rule_list(\n",
    "        rules, df_B, feature_cols\n",
    "    )\n",
    "\n",
    "    # 6) Hard rejection (no-trade or degenerate strategies)\n",
    "    if trades_A == 0 or trades_B == 0:\n",
    "        return -1e6\n",
    "\n",
    "    # 7) Drawdown on B only (future-facing risk)\n",
    "    eq_B_curve = np.asarray(eq_B_curve, dtype=float)\n",
    "    running_max = np.maximum.accumulate(eq_B_curve)\n",
    "    drawdowns = (running_max - eq_B_curve) / np.clip(running_max, 1e-12, None)\n",
    "    max_dd_B = float(np.max(drawdowns))\n",
    "\n",
    "    # ---------------- penalties ----------------\n",
    "\n",
    "    # (1) drawdown penalty (soft, realistic)\n",
    "    LAMBDA_DD = 0.4\n",
    "    penalty_dd = LAMBDA_DD * max_dd_B * STARTING_CAPITAL\n",
    "\n",
    "    # (2) complexity penalty (rules + conditions)\n",
    "    n_rules = len(rules)\n",
    "    n_conds = sum(\n",
    "        len(r.conditions)\n",
    "        for r in rules\n",
    "        if hasattr(r, \"conditions\") and r.conditions is not None\n",
    "    )\n",
    "    penalty_complexity = 1.2 * n_rules + 0.4 * n_conds\n",
    "\n",
    "    # (3) trade-count pressure (soft, on B only)\n",
    "    penalty_trades = 0.0\n",
    "    if trades_B > 120:\n",
    "        penalty_trades += 2.0 * (trades_B - 120)\n",
    "    elif trades_B < 10:\n",
    "        penalty_trades += 50.0\n",
    "\n",
    "    # 8) Final fitness (future weighted more)\n",
    "    fitness = (\n",
    "        0.4 * final_A\n",
    "        + 0.6 * final_B\n",
    "        - penalty_dd\n",
    "        - penalty_complexity\n",
    "        - penalty_trades\n",
    "    )\n",
    "\n",
    "    return float(fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kWiZwprFVkN8"
   },
   "outputs": [],
   "source": [
    "# === 6. GA: initialization ===\n",
    "\n",
    "def random_chromosome(n_features: int) -> Chromosome:\n",
    "    rule_active = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    if rule_active.sum() == 0:\n",
    "        rule_active[np.random.randint(0, MAX_RULES)] = 1\n",
    "\n",
    "    side_gene = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    tp_gene = np.random.rand(MAX_RULES)\n",
    "    sl_gene = np.random.rand(MAX_RULES)\n",
    "    size_gene = np.random.rand(MAX_RULES)  # NEW: position size genes in [0,1]\n",
    "\n",
    "    cond_active = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    for r in range(MAX_RULES):\n",
    "        if rule_active[r] == 1 and cond_active[r].sum() == 0:\n",
    "            cond_active[r, np.random.randint(0, MAX_CONDS)] = 1\n",
    "\n",
    "    feature_idx_gene = np.random.randint(0, n_features, size=(MAX_RULES, MAX_CONDS))\n",
    "    operator_gene = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    q_gene = np.random.rand(MAX_RULES, MAX_CONDS)\n",
    "\n",
    "    return Chromosome(\n",
    "        rule_active=rule_active,\n",
    "        side_gene=side_gene,\n",
    "        tp_gene=tp_gene,\n",
    "        sl_gene=sl_gene,\n",
    "        size_gene=size_gene,\n",
    "        cond_active=cond_active,\n",
    "        feature_idx_gene=feature_idx_gene,\n",
    "        operator_gene=operator_gene,\n",
    "        q_gene=q_gene,   # ⭐\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xS7M2nQXVop2"
   },
   "outputs": [],
   "source": [
    "# === 6b. Parent selection (tournament) ===\n",
    "\n",
    "def tournament_selection(population: List[Chromosome],\n",
    "                         fitnesses: List[float],\n",
    "                         k: int = TOURNAMENT_SIZE) -> Chromosome:\n",
    "    \"\"\"\n",
    "    Tournament selection: pick k random individuals, return the best.\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(population), size=k, replace=False)\n",
    "    best_idx = idxs[0]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "    for i in idxs[1:]:\n",
    "        if fitnesses[i] > best_fit:\n",
    "            best_fit = fitnesses[i]\n",
    "            best_idx = i\n",
    "    return population[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gIe7D7nSVqa7"
   },
   "outputs": [],
   "source": [
    "def crossover(\n",
    "    parent1: Chromosome,\n",
    "    parent2: Chromosome\n",
    ") -> Tuple[Chromosome, Chromosome]:\n",
    "    \"\"\"\n",
    "    Rule-aware uniform crossover with gentle condition mixing.\n",
    "    Quantile-aware (uses q_gene instead of threshold_gene).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- no crossover → clone ----------\n",
    "    if np.random.rand() >= CROSSOVER_RATE:\n",
    "        child1 = Chromosome(\n",
    "            rule_active=parent1.rule_active.copy(),\n",
    "            side_gene=parent1.side_gene.copy(),\n",
    "            tp_gene=parent1.tp_gene.copy(),\n",
    "            sl_gene=parent1.sl_gene.copy(),\n",
    "            size_gene=parent1.size_gene.copy(),\n",
    "            cond_active=parent1.cond_active.copy(),\n",
    "            feature_idx_gene=parent1.feature_idx_gene.copy(),\n",
    "            operator_gene=parent1.operator_gene.copy(),\n",
    "            q_gene=parent1.q_gene.copy(),\n",
    "        )\n",
    "        child2 = Chromosome(\n",
    "            rule_active=parent2.rule_active.copy(),\n",
    "            side_gene=parent2.side_gene.copy(),\n",
    "            tp_gene=parent2.tp_gene.copy(),\n",
    "            sl_gene=parent2.sl_gene.copy(),\n",
    "            size_gene=parent2.size_gene.copy(),\n",
    "            cond_active=parent2.cond_active.copy(),\n",
    "            feature_idx_gene=parent2.feature_idx_gene.copy(),\n",
    "            operator_gene=parent2.operator_gene.copy(),\n",
    "            q_gene=parent2.q_gene.copy(),\n",
    "        )\n",
    "        return child1, child2\n",
    "\n",
    "    # ---------- create empty children ----------\n",
    "    child1 = Chromosome(\n",
    "        rule_active=np.zeros_like(parent1.rule_active),\n",
    "        side_gene=np.zeros_like(parent1.side_gene),\n",
    "        tp_gene=np.zeros_like(parent1.tp_gene),\n",
    "        sl_gene=np.zeros_like(parent1.sl_gene),\n",
    "        size_gene=np.zeros_like(parent1.size_gene),\n",
    "        cond_active=np.zeros_like(parent1.cond_active),\n",
    "        feature_idx_gene=np.zeros_like(parent1.feature_idx_gene),\n",
    "        operator_gene=np.zeros_like(parent1.operator_gene),\n",
    "        q_gene=np.zeros_like(parent1.q_gene),\n",
    "    )\n",
    "\n",
    "    child2 = Chromosome(\n",
    "        rule_active=np.zeros_like(parent1.rule_active),\n",
    "        side_gene=np.zeros_like(parent1.side_gene),\n",
    "        tp_gene=np.zeros_like(parent1.tp_gene),\n",
    "        sl_gene=np.zeros_like(parent1.sl_gene),\n",
    "        size_gene=np.zeros_like(parent1.size_gene),\n",
    "        cond_active=np.zeros_like(parent1.cond_active),\n",
    "        feature_idx_gene=np.zeros_like(parent1.feature_idx_gene),\n",
    "        operator_gene=np.zeros_like(parent1.operator_gene),\n",
    "        q_gene=np.zeros_like(parent1.q_gene),\n",
    "    )\n",
    "\n",
    "    # ---------- rule-level uniform crossover ----------\n",
    "    for r in range(MAX_RULES):\n",
    "        if np.random.rand() < 0.5:\n",
    "            src1, src2 = parent1, parent2\n",
    "        else:\n",
    "            src1, src2 = parent2, parent1\n",
    "\n",
    "        # rule-level genes\n",
    "        child1.rule_active[r] = src1.rule_active[r]\n",
    "        child1.side_gene[r]   = src1.side_gene[r]\n",
    "        child1.tp_gene[r]     = src1.tp_gene[r]\n",
    "        child1.sl_gene[r]     = src1.sl_gene[r]\n",
    "        child1.size_gene[r]   = src1.size_gene[r]\n",
    "\n",
    "        child2.rule_active[r] = src2.rule_active[r]\n",
    "        child2.side_gene[r]   = src2.side_gene[r]\n",
    "        child2.tp_gene[r]     = src2.tp_gene[r]\n",
    "        child2.sl_gene[r]     = src2.sl_gene[r]\n",
    "        child2.size_gene[r]   = src2.size_gene[r]\n",
    "\n",
    "        # ---------- condition-level gentle mixing ----------\n",
    "        for c in range(MAX_CONDS):\n",
    "\n",
    "            # ---- child1 ----\n",
    "            if child1.rule_active[r] == 0:\n",
    "                # inactive rule → copy directly\n",
    "                child1.cond_active[r, c]      = src1.cond_active[r, c]\n",
    "                child1.feature_idx_gene[r, c] = src1.feature_idx_gene[r, c]\n",
    "                child1.operator_gene[r, c]    = src1.operator_gene[r, c]\n",
    "                child1.q_gene[r, c]           = src1.q_gene[r, c]\n",
    "            else:\n",
    "                donor = src1 if np.random.rand() < 0.7 else src2\n",
    "                child1.cond_active[r, c]      = donor.cond_active[r, c]\n",
    "                child1.feature_idx_gene[r, c] = donor.feature_idx_gene[r, c]\n",
    "                child1.operator_gene[r, c]    = donor.operator_gene[r, c]\n",
    "                child1.q_gene[r, c]           = donor.q_gene[r, c]\n",
    "\n",
    "            # ---- child2 ----\n",
    "            if child2.rule_active[r] == 0:\n",
    "                child2.cond_active[r, c]      = src2.cond_active[r, c]\n",
    "                child2.feature_idx_gene[r, c] = src2.feature_idx_gene[r, c]\n",
    "                child2.operator_gene[r, c]    = src2.operator_gene[r, c]\n",
    "                child2.q_gene[r, c]           = src2.q_gene[r, c]\n",
    "            else:\n",
    "                donor = src2 if np.random.rand() < 0.7 else src1\n",
    "                child2.cond_active[r, c]      = donor.cond_active[r, c]\n",
    "                child2.feature_idx_gene[r, c] = donor.feature_idx_gene[r, c]\n",
    "                child2.operator_gene[r, c]    = donor.operator_gene[r, c]\n",
    "                child2.q_gene[r, c]           = donor.q_gene[r, c]\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q8WP6o1zVspn"
   },
   "outputs": [],
   "source": [
    "def mutate(chrom: Chromosome, n_features: int):\n",
    "    \"\"\"\n",
    "    Quantile-aware, rule-aware mutation.\n",
    "    \"\"\"\n",
    "\n",
    "    for r in range(MAX_RULES):\n",
    "\n",
    "        # ---- mutate rule-level genes ----\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.rule_active[r] = 1 - chrom.rule_active[r]\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.side_gene[r] = 1 - chrom.side_gene[r]\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.tp_gene[r] = np.clip(\n",
    "                chrom.tp_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.001,\n",
    "                0.10,\n",
    "            )\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.sl_gene[r] = np.clip(\n",
    "                chrom.sl_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.001,\n",
    "                0.10,\n",
    "            )\n",
    "\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.size_gene[r] = np.clip(\n",
    "                chrom.size_gene[r] + np.random.normal(scale=0.05),\n",
    "                0.05,\n",
    "                0.50,\n",
    "            )\n",
    "\n",
    "        # ---- mutate condition-level genes ----\n",
    "        for c in range(MAX_CONDS):\n",
    "\n",
    "            # only mutate conditions of active rules\n",
    "            if chrom.rule_active[r] == 0:\n",
    "                continue\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.cond_active[r, c] = 1 - chrom.cond_active[r, c]\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.feature_idx_gene[r, c] = np.random.randint(0, n_features)\n",
    "\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.operator_gene[r, c] = 1 - chrom.operator_gene[r, c]\n",
    "\n",
    "            # ⭐ Quantile mutation (replaces threshold_gene)\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.q_gene[r, c] = np.clip(\n",
    "                    chrom.q_gene[r, c] + np.random.normal(scale=0.08),\n",
    "                    0.05,\n",
    "                    0.95,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9NzRZc4XVu-h"
   },
   "outputs": [],
   "source": [
    "# === 7. GA main loop ===\n",
    "\n",
    "def run_ga(df: pd.DataFrame,\n",
    "           feature_cols: List[str]\n",
    "           ) -> Tuple[Chromosome, float]:\n",
    "    \"\"\"\n",
    "    Run a simple GA to discover a good rule list.\n",
    "\n",
    "    Returns best_chromosome, best_fitness.\n",
    "    \"\"\"\n",
    "    n_features = len(feature_cols)\n",
    "\n",
    "    # --- Initialize population ---\n",
    "\n",
    "\n",
    "    initial_pop_size = POP_SIZE * 5\n",
    "    population: List[Chromosome] = [\n",
    "        random_chromosome(n_features) for _ in range(initial_pop_size)\n",
    "    ]\n",
    "\n",
    "    # Evaluate initial population\n",
    "    fitnesses = [\n",
    "        compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "    ]\n",
    "\n",
    "    sorted_idx = np.argsort(fitnesses)[::-1]  # descending\n",
    "    population = [population[i] for i in sorted_idx[:POP_SIZE]]\n",
    "    fitnesses = [fitnesses[i] for i in sorted_idx[:POP_SIZE]]\n",
    "\n",
    "\n",
    "    best_idx = int(np.argmax(fitnesses))\n",
    "    best_chrom = population[best_idx]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "\n",
    "    print(f\"Initial best fitness (from expanded pool): {best_fit:.6f}\")\n",
    "\n",
    "\n",
    "    for gen in range(1, N_GENERATIONS + 1):\n",
    "        new_population: List[Chromosome] = []\n",
    "\n",
    "        # --- Elitism: keep the best individual ---\n",
    "        new_population.append(best_chrom)\n",
    "\n",
    "        # --- Generate rest of population ---\n",
    "        while len(new_population) < POP_SIZE:\n",
    "            # Select parents\n",
    "            p1 = tournament_selection(population, fitnesses)\n",
    "            p2 = tournament_selection(population, fitnesses)\n",
    "\n",
    "            # Crossover\n",
    "            child1, child2 = crossover(p1, p2)\n",
    "\n",
    "            # Mutation\n",
    "            mutate(child1, n_features)\n",
    "            mutate(child2, n_features)\n",
    "\n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < POP_SIZE:\n",
    "                new_population.append(child2)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [\n",
    "            compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "        ]\n",
    "\n",
    "        gen_best_idx = int(np.argmax(fitnesses))\n",
    "        gen_best_fit = fitnesses[gen_best_idx]\n",
    "\n",
    "        # Update global best\n",
    "        if gen_best_fit > best_fit:\n",
    "            best_fit = gen_best_fit\n",
    "            best_chrom = population[gen_best_idx]\n",
    "\n",
    "        print(f\"Generation {gen:3d}: best fitness = {gen_best_fit:.6f}, global best = {best_fit:.6f}\")\n",
    "\n",
    "    return best_chrom, best_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MUZgrSmNVw8S"
   },
   "outputs": [],
   "source": [
    "def pretty_print_rules(rules, feature_cols):\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        cond_strs = []\n",
    "        for cond in rule.conditions:\n",
    "            feat_name = feature_cols[cond.feature_idx]\n",
    "\n",
    "            if cond.threshold is None:\n",
    "                cond_strs.append(\n",
    "                    f\"{feat_name} {cond.operator} q={cond.q:.2f}\"\n",
    "                )\n",
    "            else:\n",
    "                cond_strs.append(\n",
    "                    f\"{feat_name} {cond.operator} {cond.threshold:.4f}\"\n",
    "                )\n",
    "\n",
    "        cond_part = \" AND \".join(cond_strs)\n",
    "        print(f\"Rule {i}: IF {cond_part}\")\n",
    "        print(\n",
    "            f\"    THEN {rule.side} \"\n",
    "            f\"TP={rule.tp:.3f} SL={rule.sl:.3f} SIZE={rule.size_frac:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9E9EVODXHUE"
   },
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uWwVnxrUQoau"
   },
   "outputs": [],
   "source": [
    "# Example usage (you adapt the paths and feature names):\n",
    "FEATURE_COLS = [\n",
    "    \"vol_var_20\",\n",
    "    \"cand_close_open_ratio_1\",\n",
    "    \"rob_median_abs_dev_30\",\n",
    "    \"trend_ema_12\",\n",
    "    \"mom_roc_10\",\n",
    "    \"vol_cmf_20\",\n",
    "    \"rob_iqr_20\",\n",
    "    \"trend_ema_26\",\n",
    "    \"vol_mfi_14\",\n",
    "    \"rob_kurt_30\",\n",
    "    \"trend_sma_20\",\n",
    "    \"rob_hurst_100\",\n",
    "    \"vol_pvo_12_26\",\n",
    "    \"vol_vpt_1\",\n",
    "    \"vol_std_20\",\n",
    "    \"cand_shadow_lower_1\",\n",
    "    \"trend_tema_20\",\n",
    "    \"trend_hma_21\",\n",
    "    \"cand_range_1\",\n",
    "    \"vol_zclose_60\",\n",
    "    \"mom_willr_14\",\n",
    "    \"mom_macd_12_26\",\n",
    "    \"mom_stoch_d_14_3_3\",\n",
    "    \"cand_up_down_vol_ratio_20\",\n",
    "    \"rob_autocorr_20\",\n",
    "    \"ent_return_30\",\n",
    "    \"vol_bbw_20_2\",\n",
    "    \"vol_logret_std_20\",\n",
    "    \"vol_range_ratio_14\",\n",
    "    \"cand_shadow_upper_1\",\n",
    "    \"mom_ppo_12_26\",\n",
    "    \"trend_wma_14\",\n",
    "    \"vol_high_low_corr_20\",\n",
    "    \"vol_vroc_10\",\n",
    "    \"mom_rsi_14\"\n",
    "]\n",
    "\n",
    "DoNotUse_FEATURE_COLS = [\n",
    "    \"pivot_dynamic_reversal_score_20\",\n",
    "    \"trend_tl_confluence\",\n",
    "    \"trend_trendlines_bear_cross_5_10\",\n",
    "    \"relative_strength_pair_20\",\n",
    "    \"calmar_ratio_50\",\n",
    "    \"beta_to_index_50\",\n",
    "    \"corr_with_index_50\",\n",
    "    \"inter_corr_eth_50\",\n",
    "    \"fear_greed_index_5m\",\n",
    "    \"inter_sp500_corr_50\",\n",
    "    \"inter_market_ratio_gold\",\n",
    "    \"sentiment_smooth_index\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Preprocessing Function ===\n",
    "\n",
    "def preprocess_trading_data(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    is_train: bool = True,\n",
    "    scaler_params: Optional[dict] = None\n",
    ") -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing for trading data with features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        List of feature column names to preprocess.\n",
    "    is_train : bool\n",
    "        If True, compute statistics from data. If False, use provided scaler_params.\n",
    "    scaler_params : dict, optional\n",
    "        Dictionary containing scaling parameters (mean, std, min, max, etc.) from training set.\n",
    "        Required when is_train=False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_processed : pd.DataFrame\n",
    "        Preprocessed DataFrame.\n",
    "    scaler_params : dict\n",
    "        Dictionary with scaling parameters for each feature (for use on test set).\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if scaler_params is None:\n",
    "        scaler_params = {}\n",
    "    \n",
    "    # 1. Handle infinite values (replace with NaN for proper handling)\n",
    "    print(f\"Processing {'TRAIN' if is_train else 'TEST'} data...\")\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # Replace inf/-inf with NaN\n",
    "            df_processed[col] = df_processed[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 2. Handle missing values\n",
    "    # Strategy: Forward fill first (use previous valid value), then backward fill, then fill remaining with median\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_missing_before = df_processed[col].isna().sum()\n",
    "            \n",
    "            if n_missing_before > 0:\n",
    "                # Forward fill (use last valid observation)\n",
    "                df_processed[col] = df_processed[col].ffill()\n",
    "                \n",
    "                # Backward fill for any remaining NaNs at the start\n",
    "                df_processed[col] = df_processed[col].bfill()\n",
    "                \n",
    "                # If still NaNs exist, fill with median (computed from train or stored)\n",
    "                if df_processed[col].isna().any():\n",
    "                    if is_train:\n",
    "                        median_val = df_processed[col].median()\n",
    "                        scaler_params[f\"{col}_median\"] = median_val\n",
    "                    else:\n",
    "                        median_val = scaler_params.get(f\"{col}_median\", 0.0)\n",
    "                    \n",
    "                    df_processed[col] = df_processed[col].fillna(median_val)\n",
    "                \n",
    "                n_missing_after = df_processed[col].isna().sum()\n",
    "                if n_missing_before > 0:\n",
    "                    print(f\"  {col}: filled {n_missing_before} missing values -> {n_missing_after} remaining\")\n",
    "    \n",
    "    # 3. Remove outliers (clip to reasonable ranges based on percentiles)\n",
    "    # This prevents extreme values from distorting the strategy\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            if is_train:\n",
    "                # Compute 1st and 99th percentiles\n",
    "                lower_bound = df_processed[col].quantile(0.01)\n",
    "                upper_bound = df_processed[col].quantile(0.99)\n",
    "                scaler_params[f\"{col}_lower\"] = lower_bound\n",
    "                scaler_params[f\"{col}_upper\"] = upper_bound\n",
    "            else:\n",
    "                lower_bound = scaler_params.get(f\"{col}_lower\", df_processed[col].min())\n",
    "                upper_bound = scaler_params.get(f\"{col}_upper\", df_processed[col].max())\n",
    "            \n",
    "            # Clip values\n",
    "            df_processed[col] = df_processed[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    # 4. Standardization (Z-score normalization)\n",
    "    # This ensures all features have similar scales for threshold mapping\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            if is_train:\n",
    "                # Compute mean and std from training data\n",
    "                mean_val = df_processed[col].mean()\n",
    "                std_val = df_processed[col].std()\n",
    "                \n",
    "                # Avoid division by zero\n",
    "                if std_val == 0 or np.isnan(std_val):\n",
    "                    std_val = 1.0\n",
    "                \n",
    "                scaler_params[f\"{col}_mean\"] = mean_val\n",
    "                scaler_params[f\"{col}_std\"] = std_val\n",
    "            else:\n",
    "                # Use stored parameters from training\n",
    "                mean_val = scaler_params.get(f\"{col}_mean\", 0.0)\n",
    "                std_val = scaler_params.get(f\"{col}_std\", 1.0)\n",
    "            \n",
    "            # Apply standardization\n",
    "            df_processed[col] = (df_processed[col] - mean_val) / std_val\n",
    "    \n",
    "    # 5. Final check: ensure no NaNs or infs remain\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_invalid = df_processed[col].isna().sum() + np.isinf(df_processed[col]).sum()\n",
    "            if n_invalid > 0:\n",
    "                print(f\"  WARNING: {col} still has {n_invalid} invalid values after preprocessing!\")\n",
    "                # Final fallback: fill with 0\n",
    "                df_processed[col] = df_processed[col].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Shape: {df_processed.shape}\")\n",
    "    print(f\"Date range: {df_processed.index[0]} to {df_processed.index[-1]}\")\n",
    "    print(f\"Number of features: {len(feature_cols)}\")\n",
    "    \n",
    "    return df_processed, scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oo9cKOi0RZi6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train data shape: (52992, 36)\n",
      "Raw test data shape: (26208, 36)\n",
      "Processing TRAIN data...\n",
      "  rob_median_abs_dev_30: filled 29 missing values -> 0 remaining\n",
      "  vol_mfi_14: filled 15 missing values -> 0 remaining\n",
      "  vol_logret_std_20: filled 20 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  vol_range_ratio_14: filled 13 missing values -> 0 remaining\n",
      "  mom_stoch_d_14_3_3: filled 17 missing values -> 0 remaining\n",
      "  trend_tema_20: filled 57 missing values -> 0 remaining\n",
      "  trend_ema_26: filled 25 missing values -> 0 remaining\n",
      "  mom_ppo_12_26: filled 25 missing values -> 0 remaining\n",
      "  trend_hma_21: filled 23 missing values -> 0 remaining\n",
      "  vol_high_low_corr_20: filled 19 missing values -> 0 remaining\n",
      "  trend_wma_14: filled 13 missing values -> 0 remaining\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "  trend_ema_12: filled 11 missing values -> 0 remaining\n",
      "  vol_pvo_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  ent_return_30: filled 30 missing values -> 0 remaining\n",
      "  rob_iqr_20: filled 19 missing values -> 0 remaining\n",
      "  vol_vpt_1: filled 1 missing values -> 0 remaining\n",
      "  rob_hurst_100: filled 99 missing values -> 0 remaining\n",
      "  trend_sma_20: filled 19 missing values -> 0 remaining\n",
      "  mom_roc_10: filled 10 missing values -> 0 remaining\n",
      "  rob_kurt_30: filled 29 missing values -> 0 remaining\n",
      "  rob_autocorr_20: filled 20 missing values -> 0 remaining\n",
      "  vol_var_20: filled 19 missing values -> 0 remaining\n",
      "  cand_up_down_vol_ratio_20: filled 19 missing values -> 0 remaining\n",
      "  cand_shadow_upper_1: filled 2 missing values -> 0 remaining\n",
      "  cand_shadow_lower_1: filled 2 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  vol_std_20: filled 19 missing values -> 0 remaining\n",
      "  mom_macd_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 40 missing values -> 0 remaining\n",
      "  mom_willr_14: filled 13 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (52992, 36)\n",
      "Date range: 2025-03-01 00:00:00 to 2025-08-31 23:55:00\n",
      "Number of features: 35\n",
      "Processing TEST data...\n",
      "  rob_median_abs_dev_30: filled 29 missing values -> 0 remaining\n",
      "  vol_mfi_14: filled 13 missing values -> 0 remaining\n",
      "  vol_logret_std_20: filled 20 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  vol_range_ratio_14: filled 13 missing values -> 0 remaining\n",
      "  mom_stoch_d_14_3_3: filled 17 missing values -> 0 remaining\n",
      "  trend_tema_20: filled 57 missing values -> 0 remaining\n",
      "  trend_ema_26: filled 25 missing values -> 0 remaining\n",
      "  mom_ppo_12_26: filled 25 missing values -> 0 remaining\n",
      "  trend_hma_21: filled 23 missing values -> 0 remaining\n",
      "  vol_high_low_corr_20: filled 19 missing values -> 0 remaining\n",
      "  trend_wma_14: filled 13 missing values -> 0 remaining\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "  trend_ema_12: filled 11 missing values -> 0 remaining\n",
      "  vol_pvo_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  ent_return_30: filled 30 missing values -> 0 remaining\n",
      "  rob_iqr_20: filled 19 missing values -> 0 remaining\n",
      "  vol_vpt_1: filled 1 missing values -> 0 remaining\n",
      "  rob_hurst_100: filled 99 missing values -> 0 remaining\n",
      "  trend_sma_20: filled 19 missing values -> 0 remaining\n",
      "  mom_roc_10: filled 10 missing values -> 0 remaining\n",
      "  rob_kurt_30: filled 29 missing values -> 0 remaining\n",
      "  rob_autocorr_20: filled 20 missing values -> 0 remaining\n",
      "  vol_var_20: filled 19 missing values -> 0 remaining\n",
      "  cand_up_down_vol_ratio_20: filled 19 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  vol_std_20: filled 19 missing values -> 0 remaining\n",
      "  mom_macd_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 19 missing values -> 0 remaining\n",
      "  mom_willr_14: filled 13 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (26208, 36)\n",
      "Date range: 2025-09-01 00:00:00 to 2025-11-30 23:55:00\n",
      "Number of features: 35\n",
      "\n",
      "Final train data shape: (52992, 36)\n",
      "Final test data shape: (26208, 36)\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "df_test, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features_test.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "\n",
    "print(f\"Raw train data shape: {df.shape}\")\n",
    "print(f\"Raw test data shape: {df_test.shape}\")\n",
    "\n",
    "# Apply preprocessing\n",
    "df, scaler_params = preprocess_trading_data(df, FEATURE_COLS, is_train=True)\n",
    "df_test, _ = preprocess_trading_data(df_test, FEATURE_COLS, is_train=False, scaler_params=scaler_params)\n",
    "\n",
    "print(f\"\\nFinal train data shape: {df.shape}\")\n",
    "print(f\"Final test data shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsxYy-lfVz9-",
    "outputId": "b8aefcf5-a675-49b3-d11b-ca7fe3b7ac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best fitness (from expanded pool): 1089.695526\n",
      "Generation   1: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   2: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   3: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   4: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   5: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   6: best fitness = 1121.059122, global best = 1121.059122\n",
      "Generation   7: best fitness = 1124.291418, global best = 1124.291418\n",
      "Generation   8: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation   9: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  10: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  11: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  12: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  13: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  14: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  15: best fitness = 1133.863289, global best = 1133.863289\n",
      "Generation  16: best fitness = 1153.708991, global best = 1153.708991\n",
      "Generation  17: best fitness = 1153.708991, global best = 1153.708991\n",
      "Generation  18: best fitness = 1190.500297, global best = 1190.500297\n",
      "Generation  19: best fitness = 1190.500297, global best = 1190.500297\n",
      "Generation  20: best fitness = 1190.500297, global best = 1190.500297\n",
      "Generation  21: best fitness = 1190.500297, global best = 1190.500297\n",
      "Generation  22: best fitness = 1190.500297, global best = 1190.500297\n",
      "Generation  23: best fitness = 1199.149172, global best = 1199.149172\n",
      "Generation  24: best fitness = 1199.149172, global best = 1199.149172\n",
      "Generation  25: best fitness = 1199.149172, global best = 1199.149172\n",
      "Generation  26: best fitness = 1199.149172, global best = 1199.149172\n",
      "Generation  27: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  28: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  29: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  30: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  31: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  32: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  33: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  34: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  35: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  36: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  37: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  38: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  39: best fitness = 1231.707143, global best = 1231.707143\n",
      "Generation  40: best fitness = 1231.707143, global best = 1231.707143\n",
      "\n",
      "Best fitness found: 1231.707143\n",
      "Rule 1: IF vol_var_20 < -0.3492\n",
      "    THEN SELL TP=0.049 SL=0.013 SIZE=0.19\n",
      "Rule 2: IF rob_autocorr_20 < 0.3860 AND trend_tema_20 > 1.0662\n",
      "    THEN SELL TP=0.023 SL=0.036 SIZE=0.17\n",
      "Rule 3: IF cand_shadow_upper_1 > -0.6517\n",
      "    THEN BUY TP=0.023 SL=0.033 SIZE=0.28\n",
      "Train final equity: 1420.75, Number of positions: 280\n",
      "Test  final equity: 919.63, Number of positions: 113\n",
      "Best rules exported to rules_G09.json\n"
     ]
    }
   ],
   "source": [
    "# 1) Run GA\n",
    "best_chrom, best_fit = run_ga(df, FEATURE_COLS)\n",
    "print(f\"\\nBest fitness found: {best_fit:.6f}\")\n",
    "\n",
    "# 2) Decode and show final rule list\n",
    "best_rules = decode_chromosome(best_chrom, df, FEATURE_COLS)\n",
    "compute_condition_thresholds(best_rules, df, FEATURE_COLS)\n",
    "\n",
    "pretty_print_rules(best_rules, FEATURE_COLS)\n",
    "\n",
    "# 3) Evaluate on TRAIN and TEST (3-month out-of-sample)\n",
    "train_equity_curve, final_train_eq, n_train_trades = backtest_rule_list(\n",
    "    best_rules, df, FEATURE_COLS\n",
    ")\n",
    "\n",
    "test_equity_curve, final_test_eq, n_test_trades = backtest_rule_list(\n",
    "    best_rules, df_test, FEATURE_COLS\n",
    ")\n",
    "\n",
    "print(f\"Train final equity: {final_train_eq:.2f}, Number of positions: {n_train_trades}\")\n",
    "print(f\"Test  final equity: {final_test_eq:.2f}, Number of positions: {n_test_trades}\")\n",
    "\n",
    "# 4) Export best rules to JSON (schema-compliant)\n",
    "rules_json = {\"rules\": []}\n",
    "\n",
    "for rule in best_rules:\n",
    "    rule_dict = {\"conditions\": [], \"action\": {}}\n",
    "\n",
    "    for cond in rule.conditions:\n",
    "        feat_name = FEATURE_COLS[cond.feature_idx]\n",
    "        rule_dict[\"conditions\"].append({\n",
    "            \"feature\": feat_name,\n",
    "            \"op\": cond.operator,\n",
    "            \"threshold\": cond.threshold\n",
    "        })\n",
    "\n",
    "    rule_dict[\"action\"] = {\n",
    "        \"side\": rule.side,\n",
    "        \"tp\": rule.tp,\n",
    "        \"sl\": rule.sl,\n",
    "        \"size\": rule.size_frac\n",
    "    }\n",
    "\n",
    "    rules_json[\"rules\"].append(rule_dict)\n",
    "\n",
    "with open(\"rules_G09.json\", \"w\") as f:\n",
    "    json.dump(rules_json, f, indent=4)\n",
    "\n",
    "print(\"Best rules exported to rules_G09.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
