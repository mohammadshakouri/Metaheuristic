{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook Overview: Rule-Based Trading with Metaheuristic Rule Discovery**\n",
    "\n",
    "This notebook presents a complete demonstration of a **rule-based trading system** applied to Ethereum price data. The objective is to illustrate how **Genetic Algorithms (GA)** can be used to *automatically discover interpretable IF–THEN trading rules* based on engineered features from **Phase 1 of the course** .\n",
    "\n",
    "The implementation follows the conceptual framework introduced in the accompanying lecture materials on **Rule Discovery with Metaheuristics** .\n",
    "\n",
    "---\n",
    "\n",
    "## **Purpose of the Notebook**\n",
    "\n",
    "The notebook serves as a educational example demonstrating:\n",
    "\n",
    "1. **How trading rules are encoded as chromosomes** within a GA.\n",
    "2. **How conditions, actions, TP/SL levels, and position sizing are represented genetically.**\n",
    "3. **How a rule list is decoded and executed via a backtesting engine.**\n",
    "4. **How the GA iteratively improves candidate rule sets** using fitness feedback from historical performance.\n",
    "\n",
    "Although the demonstration uses only a subset of features, students may extend the system to incorporate the full set of engineered indicators produced in Phase 1.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chromosome Structure and Representation**\n",
    "\n",
    "Each chromosome represents a **complete ordered rule list**, where:\n",
    "\n",
    "* Each rule consists of multiple **conditions**, specifying a feature, operator, and threshold.\n",
    "* Each rule also encodes its **action parameters**:\n",
    "\n",
    "  * Take-profit (TP),\n",
    "  * Stop-loss (SL),\n",
    "  * **Fraction of capital allocated to the trade** (position size).\n",
    "* Activation flags control whether a rule or condition is included in the effective strategy.\n",
    "\n",
    "The genetic representation enables exploration of a very large combinational search space while retaining **transparent, human-readable rule structures** once decoded.\n",
    "\n",
    "---\n",
    "\n",
    "## **Training Data and Features**\n",
    "\n",
    "For this demonstration, we use only a small set of the available features to keep the example focused and computationally manageable.\n",
    "However, students are encouraged to:\n",
    "\n",
    "* Use **all available engineered features**,\n",
    "* Modify or extend the chromosome structure,\n",
    "* Experiment with different operator sets, thresholds, or rule depths.\n",
    "\n",
    "The system is fully modular, and feature selection is handled implicitly via the genetic encoding.\n",
    "\n",
    "---\n",
    "\n",
    "## **Optimization and Fitness Function**\n",
    "\n",
    "The GA is trained exclusively on the **training dataset**.\n",
    "The objective function (fitness) is defined as:\n",
    "\n",
    "> **Final equity obtained after backtesting the rule set**, starting with an initial capital of $1000.\n",
    "\n",
    "This formulation incorporates:\n",
    "\n",
    "* Profitability of trades,\n",
    "* Trading frequency,\n",
    "* Position sizing decisions,\n",
    "* Compounding through equity updates.\n",
    "\n",
    "After training, students must evaluate their discovered rule sets on the **separate test dataset** to assess out-of-sample performance and detect overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Student Instructions**\n",
    "\n",
    "* You may run this notebook directly in **Google Colab**, but remember to mount your Google Drive before accessing datasets.\n",
    "* All configuration parameters (e.g., population size, mutation rates, TP/SL ranges, position-size bounds) can be modified to explore different design choices.\n",
    "* The implementation is modular; students may:\n",
    "\n",
    "  * Add new features,\n",
    "  * Adjust how rules are represented,\n",
    "  * Implement alternative fitness functions,\n",
    "  * Replace GA with other metaheuristic algorithms such as PSO or DE.\n",
    "\n",
    "---\n",
    "\n",
    "## **Educational Goals**\n",
    "\n",
    "By working through this notebook, you will gain hands-on understanding of:\n",
    "\n",
    "* How rule-based trading systems are formalized and optimized,\n",
    "* How metaheuristic methods operate on structured, interpretable solutions,\n",
    "* How backtesting interacts with rule logic, signal generation, and position management,\n",
    "* How to evaluate trading strategies rigorously using both train and test datasets.\n",
    "\n",
    "This forms the foundation for the **Phase 2 Rule Discovery Project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwFOr1myb2ie",
    "outputId": "6fe2ad62-bf85-4b9f-cd5a-a28ce937d1ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "DGriP3ayPLD_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "xqnmtLloQizq"
   },
   "outputs": [],
   "source": [
    "# === CONFIG: rule structure, GA, and trading ===\n",
    "\n",
    "MAX_RULES = 4         # N (max rules in the rule list)\n",
    "MAX_CONDS = 2          # K (max conditions per rule)\n",
    "\n",
    "TP_MIN, TP_MAX = 0.02, 0.10   # 2% .. 40%\n",
    "SL_MIN, SL_MAX = 0.01, 0.04   # 4% .. 5%\n",
    "\n",
    "STARTING_CAPITAL = 1000.0    # starting money for the strategy\n",
    "\n",
    "POS_MIN_FRAC = 0.05          # 10% of capital per trade (min)\n",
    "POS_MAX_FRAC = 0.30          # 50% of capital per trade (max)\n",
    "\n",
    "POP_SIZE = 100\n",
    "N_GENERATIONS = 30\n",
    "TOURNAMENT_SIZE = 10\n",
    "CROSSOVER_RATE = 0.85\n",
    "MUTATION_RATE = 0.08   # base mutation probability per gene\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "0509KhbyQmMA"
   },
   "outputs": [],
   "source": [
    "# === 1. Load ETH data with engineered features ===\n",
    "\n",
    "def load_eth_features(csv_path: str,\n",
    "                      feature_cols: List[str],\n",
    "                      close_col: str = \"close\"\n",
    "                      ) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load ETH OHLCV + engineered features.\n",
    "    We keep only 'close' and selected feature columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV containing at least 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        Subset of ~50 features you want to use in the demo.\n",
    "    close_col : str\n",
    "        Name of the close price column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame indexed by time with 'close' and selected features.\n",
    "    feature_cols_used : list of str\n",
    "        The actual feature columns we keep (intersection of requested + available).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=True, index_col=0)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    if close_col.lower() not in df.columns:\n",
    "        raise ValueError(f\"Close column '{close_col}' not found in data.\")\n",
    "\n",
    "    # Intersect requested features with available columns\n",
    "    feature_cols_lower = [c.lower() for c in feature_cols]\n",
    "    available_features = [c for c in feature_cols_lower if c in df.columns]\n",
    "\n",
    "    if len(available_features) == 0:\n",
    "        raise ValueError(\"None of the requested feature columns are present in the data.\")\n",
    "\n",
    "    cols_to_keep = [close_col.lower()] + available_features\n",
    "    df = df[cols_to_keep].sort_index()\n",
    "\n",
    "    return df, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "J0q2R-qiS3e8"
   },
   "outputs": [],
   "source": [
    "# === 2. Gene and Rule structures (phenotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Condition:\n",
    "    active: bool\n",
    "    feature_idx: int\n",
    "    operator: str      # \"<\" or \">\"\n",
    "    threshold: float   # numeric threshold\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rule:\n",
    "    active: bool\n",
    "    conditions: List[Condition]\n",
    "    side: str          # \"BUY\" or \"SELL\"\n",
    "    tp: float          # take-profit as decimal (e.g. 0.03 for 3%)\n",
    "    sl: float          # stop-loss as decimal\n",
    "    size_frac: float   # fraction of current capital to allocate (0.0–1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "3bN_E5mZTHEg"
   },
   "outputs": [],
   "source": [
    "# === 2b. Chromosome representation (genotype) ===\n",
    "\n",
    "@dataclass\n",
    "class Chromosome:\n",
    "    # Rule-level genes\n",
    "    rule_active: np.ndarray      # (MAX_RULES,)  {0,1}\n",
    "    side_gene: np.ndarray        # (MAX_RULES,)  {0,1}  0=BUY, 1=SELL\n",
    "    tp_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    sl_gene: np.ndarray          # (MAX_RULES,)  [0,1]\n",
    "    size_gene: np.ndarray        # (MAX_RULES,)  [0,1]  --> position size fraction\n",
    "\n",
    "    # Condition-level genes\n",
    "    cond_active: np.ndarray      # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    feature_idx_gene: np.ndarray # (MAX_RULES, MAX_CONDS)\n",
    "    operator_gene: np.ndarray    # (MAX_RULES, MAX_CONDS)  {0,1}\n",
    "    threshold_gene: np.ndarray   # (MAX_RULES, MAX_CONDS)  [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-VRFr0mrTMJI"
   },
   "outputs": [],
   "source": [
    "# === 3. Mapping genes to actual TP/SL and thresholds ===\n",
    "\n",
    "def map_tp_gene(tp_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to TP% in [TP_MIN, TP_MAX].\"\"\"\n",
    "    return TP_MIN + tp_gene * (TP_MAX - TP_MIN)\n",
    "\n",
    "\n",
    "def map_sl_gene(sl_gene: float) -> float:\n",
    "    \"\"\"Map [0,1] gene to SL% in [SL_MIN, SL_MAX].\"\"\"\n",
    "    return SL_MIN + sl_gene * (SL_MAX - SL_MIN)\n",
    "\n",
    "\n",
    "def map_size_gene(size_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map [0,1] size_gene to a fraction of capital to allocate per trade.\n",
    "    For example, POS_MIN_FRAC=0.05, POS_MAX_FRAC=0.5 => 5%..50%.\n",
    "    \"\"\"\n",
    "    return POS_MIN_FRAC + size_gene * (POS_MAX_FRAC - POS_MIN_FRAC)\n",
    "\n",
    "\n",
    "def map_operator_gene(op_gene: int) -> str:\n",
    "    \"\"\"0 -> '<', 1 -> '>'.\"\"\"\n",
    "    return \"<\" if op_gene == 0 else \">\"\n",
    "\n",
    "\n",
    "def map_threshold_gene_to_value(feature_series: pd.Series, thr_gene: float) -> float:\n",
    "    \"\"\"\n",
    "    Map a [0,1] threshold_gene to a numeric threshold using feature quantiles.\n",
    "\n",
    "    thr_gene ~ 0.0 => low quantile (e.g. oversold RSI)\n",
    "    thr_gene ~ 1.0 => high quantile (e.g. overbought RSI)\n",
    "    \"\"\"\n",
    "    # np.nanquantile handles NaNs gracefully\n",
    "    return float(np.nanquantile(feature_series.values, thr_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "b6hGCuyETa8e"
   },
   "outputs": [],
   "source": [
    "# === 3b. Decode Chromosome to Rule List ===\n",
    "\n",
    "def decode_chromosome(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> List[Rule]:\n",
    "    rules: List[Rule] = []\n",
    "\n",
    "    for r in range(MAX_RULES):\n",
    "        if chrom.rule_active[r] == 0:\n",
    "            continue\n",
    "\n",
    "        side = \"BUY\" if chrom.side_gene[r] == 0 else \"SELL\"\n",
    "        tp = map_tp_gene(chrom.tp_gene[r])\n",
    "        sl = map_sl_gene(chrom.sl_gene[r])\n",
    "        size_frac = map_size_gene(chrom.size_gene[r])   # NEW\n",
    "\n",
    "        conds: List[Condition] = []\n",
    "        for c in range(MAX_CONDS):\n",
    "            if chrom.cond_active[r, c] == 0:\n",
    "                continue\n",
    "\n",
    "            feat_idx = int(chrom.feature_idx_gene[r, c]) % len(feature_cols)\n",
    "            feat_name = feature_cols[feat_idx]\n",
    "            feat_series = df[feat_name]\n",
    "\n",
    "            op = map_operator_gene(int(chrom.operator_gene[r, c]))\n",
    "            thr_gene = float(chrom.threshold_gene[r, c])\n",
    "            thr_value = map_threshold_gene_to_value(feat_series, thr_gene)\n",
    "\n",
    "            conds.append(\n",
    "                Condition(\n",
    "                    active=True,\n",
    "                    feature_idx=feat_idx,\n",
    "                    operator=op,\n",
    "                    threshold=thr_value,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if len(conds) == 0:\n",
    "            continue\n",
    "\n",
    "        rules.append(\n",
    "            Rule(\n",
    "                active=True,\n",
    "                conditions=conds,\n",
    "                side=side,\n",
    "                tp=tp,\n",
    "                sl=sl,\n",
    "                size_frac=size_frac,  # NEW\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "5CoyXYyWTxAQ"
   },
   "outputs": [],
   "source": [
    "# === 4. Rule evaluation ===\n",
    "\n",
    "def rule_fires(rule: Rule,\n",
    "               df: pd.DataFrame,\n",
    "               feature_cols: List[str],\n",
    "               t: int) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a rule fires at row index t.\n",
    "\n",
    "    All active conditions must be true.\n",
    "    \"\"\"\n",
    "    row = df.iloc[t]\n",
    "    for cond in rule.conditions:\n",
    "        feat_name = feature_cols[cond.feature_idx]\n",
    "        x = row[feat_name]\n",
    "\n",
    "        if np.isnan(x):\n",
    "            return False  # missing feature => don't fire\n",
    "\n",
    "        if cond.operator == \"<\":\n",
    "            if not (x < cond.threshold):\n",
    "                return False\n",
    "        else:  # \">\"\n",
    "            if not (x > cond.threshold):\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oPAdngejVHJ1"
   },
   "outputs": [],
   "source": [
    "def backtest_rule_list(\n",
    "    rules: List[Rule],\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    starting_capital: float = STARTING_CAPITAL\n",
    ") -> Tuple[List[float], float]:\n",
    "    \"\"\"\n",
    "    Backtest a rule list with capital and position sizing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trade_returns : list of float\n",
    "        Per-trade returns (in % terms, like before).\n",
    "    final_equity : float\n",
    "        Final money after all trades.\n",
    "    \"\"\"\n",
    "    if len(rules) == 0:\n",
    "        return [], starting_capital\n",
    "\n",
    "    close = df[\"close\"].values\n",
    "    n = len(df)\n",
    "\n",
    "    equity = starting_capital\n",
    "\n",
    "    position = 0          # 0 = flat, +1 = long, -1 = short\n",
    "    entry_price = None\n",
    "    entry_rule: Optional[Rule] = None\n",
    "    entry_capital = None  # amount of capital allocated to this trade\n",
    "\n",
    "    trade_returns: List[float] = []\n",
    "\n",
    "    for t in range(n):\n",
    "        price = close[t]\n",
    "        if np.isnan(price):\n",
    "            continue\n",
    "\n",
    "        if position == 0:\n",
    "            # --- FLAT: look for entry ---\n",
    "            for rule in rules:\n",
    "                if rule_fires(rule, df, feature_cols, t):\n",
    "                    # Capital to allocate = fraction of current equity\n",
    "                    size_frac = rule.size_frac\n",
    "                    trade_capital = equity * size_frac\n",
    "\n",
    "                    if trade_capital <= 0:\n",
    "                        break  # nothing to allocate\n",
    "\n",
    "                    position = 1 if rule.side == \"BUY\" else -1\n",
    "                    entry_price = price\n",
    "                    entry_rule = rule\n",
    "                    entry_capital = trade_capital\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            # --- IN POSITION: manage trade ---\n",
    "            assert entry_rule is not None and entry_price is not None and entry_capital is not None\n",
    "\n",
    "            # Return in direction of position (+ for profit)\n",
    "            ret = position * (price / entry_price - 1.0)\n",
    "\n",
    "            tp_hit = ret >= entry_rule.tp\n",
    "            sl_hit = ret <= -entry_rule.sl\n",
    "\n",
    "            if tp_hit or sl_hit:\n",
    "                # Close trade\n",
    "                pnl = ret * entry_capital      # profit or loss in dollars\n",
    "                equity += pnl                  # update money\n",
    "                trade_returns.append(ret)\n",
    "\n",
    "                # Reset position\n",
    "                position = 0\n",
    "                entry_price = None\n",
    "                entry_rule = None\n",
    "                entry_capital = None\n",
    "\n",
    "    return trade_returns, equity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YF-8MCYVase"
   },
   "outputs": [],
   "source": [
    "# def compute_fitness(\n",
    "#     chrom: Chromosome,\n",
    "#     df: pd.DataFrame,\n",
    "#     feature_cols: List[str]\n",
    "# ) -> float:\n",
    "#     \"\"\"\n",
    "#     Decode chromosome -> rule list -> backtest -> final equity.\n",
    "\n",
    "#     Fitness = final money (higher is better).\n",
    "#     \"\"\"\n",
    "#     rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "#     trade_returns, final_equity = backtest_rule_list(\n",
    "#         rules, df, feature_cols, starting_capital=STARTING_CAPITAL\n",
    "#     )\n",
    "\n",
    "#     # Optional: if you want to slightly penalize \"do nothing\" strategies:\n",
    "#     if len(trade_returns) == 0:\n",
    "#         return STARTING_CAPITAL - 1.0  # tiny penalty\n",
    "\n",
    "#     return final_equity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def compute_fitness(\n",
    "    chrom: Chromosome,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> float:\n",
    "    rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "    trade_returns, final_equity = backtest_rule_list(\n",
    "        rules, df, feature_cols, starting_capital=STARTING_CAPITAL\n",
    "    )\n",
    "\n",
    "    # do-nothing penalty\n",
    "    if len(trade_returns) == 0:\n",
    "        return STARTING_CAPITAL - 5.0\n",
    "\n",
    "    rets = np.asarray(trade_returns, dtype=float)\n",
    "\n",
    "    # equity curve (per-trade compounding)\n",
    "    equity_curve = STARTING_CAPITAL * np.cumprod(1.0 + rets)\n",
    "    running_max = np.maximum.accumulate(equity_curve)\n",
    "    drawdowns = (running_max - equity_curve) / np.clip(running_max, 1e-12, None)\n",
    "    max_dd = float(np.max(drawdowns))\n",
    "\n",
    "    # 1) drawdown penalty\n",
    "    LAMBDA_DD = 0.9\n",
    "    penalty_dd = LAMBDA_DD * max_dd * STARTING_CAPITAL\n",
    "\n",
    "    # 2) complexity penalty\n",
    "    n_rules = len(rules)\n",
    "    n_conds = 0\n",
    "    for r in rules:\n",
    "        if hasattr(r, \"conditions\"):\n",
    "            n_conds += len(r.conditions)\n",
    "        elif isinstance(r, dict) and \"conditions\" in r:\n",
    "            n_conds += len(r[\"conditions\"])\n",
    "\n",
    "    LAMBDA_RULE = 2.5\n",
    "    LAMBDA_COND = 1.2\n",
    "    penalty_complexity = (LAMBDA_RULE * n_rules) + (LAMBDA_COND * n_conds)\n",
    "\n",
    "    # 3) trade-count penalty centered around ~60 trades\n",
    "    n_trades = len(rets)\n",
    "    TARGET_TRADES = 60\n",
    "    TOL = 25  # within 35..85 trades is \"fine\"\n",
    "\n",
    "    # quadratic penalty outside the tolerance band\n",
    "    deviation = max(0, abs(n_trades - TARGET_TRADES) - TOL)\n",
    "    LAMBDA_TRADES = 0.15\n",
    "    penalty_trades = LAMBDA_TRADES * (deviation ** 2)\n",
    "\n",
    "    fitness = float(final_equity) - penalty_dd - penalty_complexity - penalty_trades\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "kWiZwprFVkN8"
   },
   "outputs": [],
   "source": [
    "# === 6. GA: initialization ===\n",
    "\n",
    "def random_chromosome(n_features: int) -> Chromosome:\n",
    "    rule_active = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    if rule_active.sum() == 0:\n",
    "        rule_active[np.random.randint(0, MAX_RULES)] = 1\n",
    "\n",
    "    side_gene = np.random.randint(0, 2, size=(MAX_RULES,))\n",
    "    tp_gene = np.random.rand(MAX_RULES)\n",
    "    sl_gene = np.random.rand(MAX_RULES)\n",
    "    size_gene = np.random.rand(MAX_RULES)  # NEW: position size genes in [0,1]\n",
    "\n",
    "    cond_active = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    for r in range(MAX_RULES):\n",
    "        if rule_active[r] == 1 and cond_active[r].sum() == 0:\n",
    "            cond_active[r, np.random.randint(0, MAX_CONDS)] = 1\n",
    "\n",
    "    feature_idx_gene = np.random.randint(0, n_features, size=(MAX_RULES, MAX_CONDS))\n",
    "    operator_gene = np.random.randint(0, 2, size=(MAX_RULES, MAX_CONDS))\n",
    "    threshold_gene = np.random.rand(MAX_RULES, MAX_CONDS)\n",
    "\n",
    "    return Chromosome(\n",
    "        rule_active=rule_active,\n",
    "        side_gene=side_gene,\n",
    "        tp_gene=tp_gene,\n",
    "        sl_gene=sl_gene,\n",
    "        size_gene=size_gene,          # NEW\n",
    "        cond_active=cond_active,\n",
    "        feature_idx_gene=feature_idx_gene,\n",
    "        operator_gene=operator_gene,\n",
    "        threshold_gene=threshold_gene,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "xS7M2nQXVop2"
   },
   "outputs": [],
   "source": [
    "# === 6b. Parent selection (tournament) ===\n",
    "\n",
    "def tournament_selection(population: List[Chromosome],\n",
    "                         fitnesses: List[float],\n",
    "                         k: int = TOURNAMENT_SIZE) -> Chromosome:\n",
    "    \"\"\"\n",
    "    Tournament selection: pick k random individuals, return the best.\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(population), size=k, replace=False)\n",
    "    best_idx = idxs[0]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "    for i in idxs[1:]:\n",
    "        if fitnesses[i] > best_fit:\n",
    "            best_fit = fitnesses[i]\n",
    "            best_idx = i\n",
    "    return population[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "gIe7D7nSVqa7"
   },
   "outputs": [],
   "source": [
    "def crossover(parent1: Chromosome,\n",
    "              parent2: Chromosome) -> Tuple[Chromosome, Chromosome]:\n",
    "    \"\"\"\n",
    "    Rule-Level Crossover: Swaps entire rules between parents at a single, \n",
    "    random crossover point, ensuring rule structure coherence.\n",
    "    \"\"\"\n",
    "    # Create copies for children\n",
    "    child1 = Chromosome(\n",
    "        rule_active=parent1.rule_active.copy(),\n",
    "        side_gene=parent1.side_gene.copy(),\n",
    "        tp_gene=parent1.tp_gene.copy(),\n",
    "        sl_gene=parent1.sl_gene.copy(),\n",
    "        size_gene=parent1.size_gene.copy(),\n",
    "        cond_active=parent1.cond_active.copy(),\n",
    "        feature_idx_gene=parent1.feature_idx_gene.copy(),\n",
    "        operator_gene=parent1.operator_gene.copy(),\n",
    "        threshold_gene=parent1.threshold_gene.copy(),\n",
    "    )\n",
    "\n",
    "    child2 = Chromosome(\n",
    "        rule_active=parent2.rule_active.copy(),\n",
    "        side_gene=parent2.side_gene.copy(),\n",
    "        tp_gene=parent2.tp_gene.copy(),\n",
    "        sl_gene=parent2.sl_gene.copy(),\n",
    "        size_gene=parent2.size_gene.copy(),\n",
    "        cond_active=parent2.cond_active.copy(),\n",
    "        feature_idx_gene=parent2.feature_idx_gene.copy(),\n",
    "        operator_gene=parent2.operator_gene.copy(),\n",
    "        threshold_gene=parent2.threshold_gene.copy(),\n",
    "    )\n",
    "\n",
    "    # Apply crossover only if a random number is below the rate\n",
    "    if np.random.rand() < CROSSOVER_RATE:\n",
    "        \n",
    "        # 1. Choose a crossover point (between 1 and MAX_RULES - 1)\n",
    "        if MAX_RULES <= 1:\n",
    "            return child1, child2 \n",
    "            \n",
    "        crossover_point = np.random.randint(1, MAX_RULES)\n",
    "\n",
    "        # 2. Swap Rule-Level Genes (1D arrays: rule_active, side, tp, sl, size)\n",
    "        \n",
    "        # Swap the tail segment (from crossover_point onwards)\n",
    "        genes_to_swap = [\n",
    "            (child1.rule_active, child2.rule_active),\n",
    "            (child1.side_gene, child2.side_gene),\n",
    "            (child1.tp_gene, child2.tp_gene),\n",
    "            (child1.sl_gene, child2.sl_gene),\n",
    "            (child1.size_gene, child2.size_gene),\n",
    "        ]\n",
    "        \n",
    "        for g1, g2 in genes_to_swap:\n",
    "            temp = g1[crossover_point:].copy()\n",
    "            g1[crossover_point:] = g2[crossover_point:]\n",
    "            g2[crossover_point:] = temp\n",
    "\n",
    "        # 3. Swap Condition-Level Genes (2D arrays: cond_active, feature_idx, operator, threshold)\n",
    "        \n",
    "        # Swap the tail segment of the 2D arrays (rules at the end)\n",
    "        array_genes_to_swap = [\n",
    "            (child1.cond_active, child2.cond_active),\n",
    "            (child1.feature_idx_gene, child2.feature_idx_gene),\n",
    "            (child1.operator_gene, child2.operator_gene),\n",
    "            (child1.threshold_gene, child2.threshold_gene),\n",
    "        ]\n",
    "\n",
    "        for a1, a2 in array_genes_to_swap:\n",
    "            temp = a1[crossover_point:, :].copy()\n",
    "            a1[crossover_point:, :] = a2[crossover_point:, :]\n",
    "            a2[crossover_point:, :] = temp\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Q8WP6o1zVspn"
   },
   "outputs": [],
   "source": [
    "# === 6d. Mutation ===\n",
    "\n",
    "def mutate(chrom: Chromosome, n_features: int) -> None:\n",
    "    \"\"\"\n",
    "    In-place mutation of a chromosome.\n",
    "    \"\"\"\n",
    "    # Rule activation bits\n",
    "    for r in range(MAX_RULES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.rule_active[r] = 1 - chrom.rule_active[r]  # flip 0/1\n",
    "\n",
    "    # Ensure at least one active rule\n",
    "    if chrom.rule_active.sum() == 0:\n",
    "        chrom.rule_active[np.random.randint(0, MAX_RULES)] = 1\n",
    "\n",
    "    # Side (BUY/SELL)\n",
    "    for r in range(MAX_RULES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.side_gene[r] = 1 - chrom.side_gene[r]\n",
    "\n",
    "    # TP/SL genes (small Gaussian noise)\n",
    "    for r in range(MAX_RULES):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.tp_gene[r] = np.clip(\n",
    "                chrom.tp_gene[r] + np.random.normal(scale=0.1), 0.0, 1.0\n",
    "            )\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.sl_gene[r] = np.clip(\n",
    "                chrom.sl_gene[r] + np.random.normal(scale=0.1), 0.0, 1.0\n",
    "            )\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            chrom.size_gene[r] = np.clip(\n",
    "                chrom.size_gene[r] + np.random.normal(scale=0.1), 0.0, 1.0\n",
    "            )\n",
    "\n",
    "    # Condition activation bits\n",
    "    for r in range(MAX_RULES):\n",
    "        for c in range(MAX_CONDS):\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.cond_active[r, c] = 1 - chrom.cond_active[r, c]\n",
    "\n",
    "        # Ensure at least one active condition per active rule\n",
    "        if chrom.rule_active[r] == 1 and chrom.cond_active[r].sum() == 0:\n",
    "            chrom.cond_active[r, np.random.randint(0, MAX_CONDS)] = 1\n",
    "\n",
    "    # Feature index, operator, threshold_gene\n",
    "    for r in range(MAX_RULES):\n",
    "        for c in range(MAX_CONDS):\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.feature_idx_gene[r, c] = np.random.randint(0, n_features)\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.operator_gene[r, c] = 1 - chrom.operator_gene[r, c]\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                chrom.threshold_gene[r, c] = np.clip(\n",
    "                    chrom.threshold_gene[r, c] + np.random.normal(scale=0.1),\n",
    "                    0.0,\n",
    "                    1.0,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "9NzRZc4XVu-h"
   },
   "outputs": [],
   "source": [
    "# === 7. GA main loop ===\n",
    "\n",
    "def run_ga(df: pd.DataFrame,\n",
    "           feature_cols: List[str]\n",
    "           ) -> Tuple[Chromosome, float]:\n",
    "    \"\"\"\n",
    "    Run a simple GA to discover a good rule list.\n",
    "\n",
    "    Returns best_chromosome, best_fitness.\n",
    "    \"\"\"\n",
    "    n_features = len(feature_cols)\n",
    "\n",
    "    # --- Initialize population ---\n",
    "\n",
    "\n",
    "    initial_pop_size = POP_SIZE * 5\n",
    "    population: List[Chromosome] = [\n",
    "        random_chromosome(n_features) for _ in range(initial_pop_size)\n",
    "    ]\n",
    "\n",
    "    # Evaluate initial population\n",
    "    fitnesses = [\n",
    "        compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "    ]\n",
    "\n",
    "    sorted_idx = np.argsort(fitnesses)[::-1]  # descending\n",
    "    population = [population[i] for i in sorted_idx[:POP_SIZE]]\n",
    "    fitnesses = [fitnesses[i] for i in sorted_idx[:POP_SIZE]]\n",
    "\n",
    "\n",
    "    best_idx = int(np.argmax(fitnesses))\n",
    "    best_chrom = population[best_idx]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "\n",
    "    print(f\"Initial best fitness (from expanded pool): {best_fit:.6f}\")\n",
    "\n",
    "\n",
    "    for gen in range(1, N_GENERATIONS + 1):\n",
    "        new_population: List[Chromosome] = []\n",
    "\n",
    "        # --- Elitism: keep the best individual ---\n",
    "        new_population.append(best_chrom)\n",
    "\n",
    "        # --- Generate rest of population ---\n",
    "        while len(new_population) < POP_SIZE:\n",
    "            # Select parents\n",
    "            p1 = tournament_selection(population, fitnesses)\n",
    "            p2 = tournament_selection(population, fitnesses)\n",
    "\n",
    "            # Crossover\n",
    "            child1, child2 = crossover(p1, p2)\n",
    "\n",
    "            # Mutation\n",
    "            mutate(child1, n_features)\n",
    "            mutate(child2, n_features)\n",
    "\n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < POP_SIZE:\n",
    "                new_population.append(child2)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [\n",
    "            compute_fitness(chrom, df, feature_cols) for chrom in population\n",
    "        ]\n",
    "\n",
    "        gen_best_idx = int(np.argmax(fitnesses))\n",
    "        gen_best_fit = fitnesses[gen_best_idx]\n",
    "\n",
    "        # Update global best\n",
    "        if gen_best_fit > best_fit:\n",
    "            best_fit = gen_best_fit\n",
    "            best_chrom = population[gen_best_idx]\n",
    "\n",
    "        print(f\"Generation {gen:3d}: best fitness = {gen_best_fit:.6f}, global best = {best_fit:.6f}\")\n",
    "\n",
    "    return best_chrom, best_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "MUZgrSmNVw8S"
   },
   "outputs": [],
   "source": [
    "# === 8. Pretty-print rule list ===\n",
    "\n",
    "def pretty_print_rules(chrom: Chromosome,\n",
    "                       df: pd.DataFrame,\n",
    "                       feature_cols: List[str]) -> None:\n",
    "    rules = decode_chromosome(chrom, df, feature_cols)\n",
    "\n",
    "    if len(rules) == 0:\n",
    "        print(\"No active rules.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== Discovered Rule List (ordered) ===\\n\")\n",
    "    for i, rule in enumerate(rules, start=1):\n",
    "        cond_strs = []\n",
    "        for cond in rule.conditions:\n",
    "            feat_name = feature_cols[cond.feature_idx]\n",
    "            cond_strs.append(f\"{feat_name} {cond.operator} {cond.threshold:.4f}\")\n",
    "\n",
    "        cond_part = \" AND \".join(cond_strs)\n",
    "        print(f\"Rule {i}: IF {cond_part}\")\n",
    "        print(f\"        THEN {rule.side} with TP = {rule.tp*100:.1f}%, SL = {rule.sl*100:.1f}%, Capital Fraction = {rule.size_frac*100:.1f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9E9EVODXHUE"
   },
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "uWwVnxrUQoau"
   },
   "outputs": [],
   "source": [
    "# Example usage (you adapt the paths and feature names):\n",
    "FEATURE_COLS = [\n",
    "    \"vol_var_20\",\n",
    "    \"cand_close_open_ratio_1\",\n",
    "    \"rob_median_abs_dev_30\",\n",
    "    \"trend_ema_12\",\n",
    "    \"mom_roc_10\",\n",
    "    \"vol_cmf_20\",\n",
    "    \"rob_iqr_20\",\n",
    "    \"trend_ema_26\",\n",
    "    \"vol_mfi_14\",\n",
    "    \"rob_kurt_30\",\n",
    "    \"trend_sma_20\",\n",
    "    \"rob_hurst_100\",\n",
    "    \"vol_pvo_12_26\",\n",
    "    \"vol_vpt_1\",\n",
    "    \"vol_std_20\",\n",
    "    \"cand_shadow_lower_1\",\n",
    "    \"trend_tema_20\",\n",
    "    \"trend_hma_21\",\n",
    "    \"cand_range_1\",\n",
    "    \"vol_zclose_60\",\n",
    "    \"mom_willr_14\",\n",
    "    \"mom_macd_12_26\",\n",
    "    \"mom_stoch_d_14_3_3\",\n",
    "    \"cand_up_down_vol_ratio_20\",\n",
    "    \"rob_autocorr_20\",\n",
    "    \"ent_return_30\",\n",
    "    \"vol_bbw_20_2\",\n",
    "    \"vol_logret_std_20\",\n",
    "    \"vol_range_ratio_14\",\n",
    "    \"cand_shadow_upper_1\",\n",
    "    \"mom_ppo_12_26\",\n",
    "    \"trend_wma_14\",\n",
    "    \"vol_high_low_corr_20\",\n",
    "    \"vol_vroc_10\",\n",
    "    \"mom_rsi_14\"\n",
    "]\n",
    "\n",
    "DoNotUse_FEATURE_COLS = [\n",
    "    \"pivot_dynamic_reversal_score_20\",\n",
    "    \"trend_tl_confluence\",\n",
    "    \"trend_trendlines_bear_cross_5_10\",\n",
    "    \"relative_strength_pair_20\",\n",
    "    \"calmar_ratio_50\",\n",
    "    \"beta_to_index_50\",\n",
    "    \"corr_with_index_50\",\n",
    "    \"inter_corr_eth_50\",\n",
    "    \"fear_greed_index_5m\",\n",
    "    \"inter_sp500_corr_50\",\n",
    "    \"inter_market_ratio_gold\",\n",
    "    \"sentiment_smooth_index\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Preprocessing Function ===\n",
    "\n",
    "def preprocess_trading_data(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    is_train: bool = True,\n",
    "    scaler_params: Optional[dict] = None\n",
    ") -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing for trading data with features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'close' and feature columns.\n",
    "    feature_cols : list of str\n",
    "        List of feature column names to preprocess.\n",
    "    is_train : bool\n",
    "        If True, compute statistics from data. If False, use provided scaler_params.\n",
    "    scaler_params : dict, optional\n",
    "        Dictionary containing scaling parameters (mean, std, min, max, etc.) from training set.\n",
    "        Required when is_train=False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_processed : pd.DataFrame\n",
    "        Preprocessed DataFrame.\n",
    "    scaler_params : dict\n",
    "        Dictionary with scaling parameters for each feature (for use on test set).\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if scaler_params is None:\n",
    "        scaler_params = {}\n",
    "    \n",
    "    # 1. Handle infinite values (replace with NaN for proper handling)\n",
    "    print(f\"Processing {'TRAIN' if is_train else 'TEST'} data...\")\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # Replace inf/-inf with NaN\n",
    "            df_processed[col] = df_processed[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 2. Handle missing values\n",
    "    # Strategy: Forward fill first (use previous valid value), then backward fill, then fill remaining with median\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_missing_before = df_processed[col].isna().sum()\n",
    "            \n",
    "            if n_missing_before > 0:\n",
    "                # Forward fill (use last valid observation)\n",
    "                df_processed[col] = df_processed[col].ffill()\n",
    "                \n",
    "                # Backward fill for any remaining NaNs at the start\n",
    "                df_processed[col] = df_processed[col].bfill()\n",
    "                \n",
    "                # If still NaNs exist, fill with median (computed from train or stored)\n",
    "                if df_processed[col].isna().any():\n",
    "                    if is_train:\n",
    "                        median_val = df_processed[col].median()\n",
    "                        scaler_params[f\"{col}_median\"] = median_val\n",
    "                    else:\n",
    "                        median_val = scaler_params.get(f\"{col}_median\", 0.0)\n",
    "                    \n",
    "                    df_processed[col] = df_processed[col].fillna(median_val)\n",
    "                \n",
    "                n_missing_after = df_processed[col].isna().sum()\n",
    "                if n_missing_before > 0:\n",
    "                    print(f\"  {col}: filled {n_missing_before} missing values -> {n_missing_after} remaining\")\n",
    "    \n",
    "    # 3. Remove outliers (clip to reasonable ranges based on percentiles)\n",
    "    # This prevents extreme values from distorting the strategy\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            if is_train:\n",
    "                # Compute 1st and 99th percentiles\n",
    "                lower_bound = df_processed[col].quantile(0.01)\n",
    "                upper_bound = df_processed[col].quantile(0.99)\n",
    "                scaler_params[f\"{col}_lower\"] = lower_bound\n",
    "                scaler_params[f\"{col}_upper\"] = upper_bound\n",
    "            else:\n",
    "                lower_bound = scaler_params.get(f\"{col}_lower\", df_processed[col].min())\n",
    "                upper_bound = scaler_params.get(f\"{col}_upper\", df_processed[col].max())\n",
    "            \n",
    "            # Clip values\n",
    "            df_processed[col] = df_processed[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    # 4. Standardization (Z-score normalization)\n",
    "    # This ensures all features have similar scales for threshold mapping\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            if is_train:\n",
    "                # Compute mean and std from training data\n",
    "                mean_val = df_processed[col].mean()\n",
    "                std_val = df_processed[col].std()\n",
    "                \n",
    "                # Avoid division by zero\n",
    "                if std_val == 0 or np.isnan(std_val):\n",
    "                    std_val = 1.0\n",
    "                \n",
    "                scaler_params[f\"{col}_mean\"] = mean_val\n",
    "                scaler_params[f\"{col}_std\"] = std_val\n",
    "            else:\n",
    "                # Use stored parameters from training\n",
    "                mean_val = scaler_params.get(f\"{col}_mean\", 0.0)\n",
    "                std_val = scaler_params.get(f\"{col}_std\", 1.0)\n",
    "            \n",
    "            # Apply standardization\n",
    "            df_processed[col] = (df_processed[col] - mean_val) / std_val\n",
    "    \n",
    "    # 5. Final check: ensure no NaNs or infs remain\n",
    "    for col in feature_cols:\n",
    "        if col in df_processed.columns:\n",
    "            n_invalid = df_processed[col].isna().sum() + np.isinf(df_processed[col]).sum()\n",
    "            if n_invalid > 0:\n",
    "                print(f\"  WARNING: {col} still has {n_invalid} invalid values after preprocessing!\")\n",
    "                # Final fallback: fill with 0\n",
    "                df_processed[col] = df_processed[col].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Shape: {df_processed.shape}\")\n",
    "    print(f\"Date range: {df_processed.index[0]} to {df_processed.index[-1]}\")\n",
    "    print(f\"Number of features: {len(feature_cols)}\")\n",
    "    \n",
    "    return df_processed, scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oo9cKOi0RZi6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train data shape: (52992, 36)\n",
      "Raw test data shape: (26208, 36)\n",
      "Processing TRAIN data...\n",
      "  cand_shadow_lower_1: filled 2 missing values -> 0 remaining\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "  vol_range_ratio_14: filled 13 missing values -> 0 remaining\n",
      "  vol_mfi_14: filled 15 missing values -> 0 remaining\n",
      "  rob_iqr_20: filled 19 missing values -> 0 remaining\n",
      "  rob_kurt_30: filled 29 missing values -> 0 remaining\n",
      "  vol_vpt_1: filled 1 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  rob_median_abs_dev_30: filled 29 missing values -> 0 remaining\n",
      "  cand_shadow_upper_1: filled 2 missing values -> 0 remaining\n",
      "  trend_wma_14: filled 13 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  trend_ema_26: filled 25 missing values -> 0 remaining\n",
      "  vol_var_20: filled 19 missing values -> 0 remaining\n",
      "  mom_roc_10: filled 10 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 40 missing values -> 0 remaining\n",
      "  vol_std_20: filled 19 missing values -> 0 remaining\n",
      "  mom_macd_12_26: filled 25 missing values -> 0 remaining\n",
      "  rob_autocorr_20: filled 20 missing values -> 0 remaining\n",
      "  ent_return_30: filled 30 missing values -> 0 remaining\n",
      "  mom_willr_14: filled 13 missing values -> 0 remaining\n",
      "  trend_ema_12: filled 11 missing values -> 0 remaining\n",
      "  trend_sma_20: filled 19 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  trend_tema_20: filled 57 missing values -> 0 remaining\n",
      "  vol_pvo_12_26: filled 25 missing values -> 0 remaining\n",
      "  mom_stoch_d_14_3_3: filled 17 missing values -> 0 remaining\n",
      "  rob_hurst_100: filled 99 missing values -> 0 remaining\n",
      "  vol_logret_std_20: filled 20 missing values -> 0 remaining\n",
      "  mom_ppo_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_high_low_corr_20: filled 19 missing values -> 0 remaining\n",
      "  cand_up_down_vol_ratio_20: filled 19 missing values -> 0 remaining\n",
      "  trend_hma_21: filled 23 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (52992, 36)\n",
      "Date range: 2025-03-01 00:00:00 to 2025-08-31 23:55:00\n",
      "Number of features: 35\n",
      "Processing TEST data...\n",
      "  vol_bbw_20_2: filled 19 missing values -> 0 remaining\n",
      "  vol_range_ratio_14: filled 13 missing values -> 0 remaining\n",
      "  vol_mfi_14: filled 13 missing values -> 0 remaining\n",
      "  rob_iqr_20: filled 19 missing values -> 0 remaining\n",
      "  rob_kurt_30: filled 29 missing values -> 0 remaining\n",
      "  vol_vpt_1: filled 1 missing values -> 0 remaining\n",
      "  mom_rsi_14: filled 14 missing values -> 0 remaining\n",
      "  rob_median_abs_dev_30: filled 29 missing values -> 0 remaining\n",
      "  trend_wma_14: filled 13 missing values -> 0 remaining\n",
      "  vol_vroc_10: filled 10 missing values -> 0 remaining\n",
      "  trend_ema_26: filled 25 missing values -> 0 remaining\n",
      "  vol_var_20: filled 19 missing values -> 0 remaining\n",
      "  mom_roc_10: filled 10 missing values -> 0 remaining\n",
      "  vol_cmf_20: filled 19 missing values -> 0 remaining\n",
      "  vol_std_20: filled 19 missing values -> 0 remaining\n",
      "  mom_macd_12_26: filled 25 missing values -> 0 remaining\n",
      "  rob_autocorr_20: filled 20 missing values -> 0 remaining\n",
      "  ent_return_30: filled 30 missing values -> 0 remaining\n",
      "  mom_willr_14: filled 13 missing values -> 0 remaining\n",
      "  trend_ema_12: filled 11 missing values -> 0 remaining\n",
      "  trend_sma_20: filled 19 missing values -> 0 remaining\n",
      "  vol_zclose_60: filled 59 missing values -> 0 remaining\n",
      "  trend_tema_20: filled 57 missing values -> 0 remaining\n",
      "  vol_pvo_12_26: filled 25 missing values -> 0 remaining\n",
      "  mom_stoch_d_14_3_3: filled 17 missing values -> 0 remaining\n",
      "  rob_hurst_100: filled 99 missing values -> 0 remaining\n",
      "  vol_logret_std_20: filled 20 missing values -> 0 remaining\n",
      "  mom_ppo_12_26: filled 25 missing values -> 0 remaining\n",
      "  vol_high_low_corr_20: filled 19 missing values -> 0 remaining\n",
      "  cand_up_down_vol_ratio_20: filled 19 missing values -> 0 remaining\n",
      "  trend_hma_21: filled 23 missing values -> 0 remaining\n",
      "Preprocessing complete. Shape: (26208, 36)\n",
      "Date range: 2025-09-01 00:00:00 to 2025-11-30 23:55:00\n",
      "Number of features: 35\n",
      "\n",
      "Final train data shape: (52992, 36)\n",
      "Final test data shape: (26208, 36)\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "df_test, FEATURE_COLS = load_eth_features(\"./eth_5m_with_features_test.csv\", list(set(FEATURE_COLS) - set(DoNotUse_FEATURE_COLS)))\n",
    "\n",
    "print(f\"Raw train data shape: {df.shape}\")\n",
    "print(f\"Raw test data shape: {df_test.shape}\")\n",
    "\n",
    "# Apply preprocessing\n",
    "df, scaler_params = preprocess_trading_data(df, FEATURE_COLS, is_train=True)\n",
    "df_test, _ = preprocess_trading_data(df_test, FEATURE_COLS, is_train=False, scaler_params=scaler_params)\n",
    "\n",
    "print(f\"\\nFinal train data shape: {df.shape}\")\n",
    "print(f\"Final test data shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsxYy-lfVz9-",
    "outputId": "b8aefcf5-a675-49b3-d11b-ca7fe3b7ac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best fitness (from expanded pool): 995.000000\n",
      "Generation   1: best fitness = 1004.243852, global best = 1004.243852\n",
      "Generation   2: best fitness = 1007.943852, global best = 1007.943852\n",
      "Generation   3: best fitness = 1056.958239, global best = 1056.958239\n",
      "Generation   4: best fitness = 1062.389913, global best = 1062.389913\n",
      "Generation   5: best fitness = 1165.601221, global best = 1165.601221\n",
      "Generation   6: best fitness = 1239.166312, global best = 1239.166312\n",
      "Generation   7: best fitness = 1293.424530, global best = 1293.424530\n",
      "Generation   8: best fitness = 1391.146358, global best = 1391.146358\n",
      "Generation   9: best fitness = 1391.146358, global best = 1391.146358\n",
      "Generation  10: best fitness = 1393.097332, global best = 1393.097332\n",
      "Generation  11: best fitness = 1393.097332, global best = 1393.097332\n",
      "Generation  12: best fitness = 1586.017470, global best = 1586.017470\n",
      "Generation  13: best fitness = 1586.017470, global best = 1586.017470\n",
      "Generation  14: best fitness = 1586.017470, global best = 1586.017470\n",
      "Generation  15: best fitness = 1643.477202, global best = 1643.477202\n",
      "Generation  16: best fitness = 1643.477202, global best = 1643.477202\n",
      "Generation  17: best fitness = 1643.477202, global best = 1643.477202\n",
      "Generation  18: best fitness = 1707.895702, global best = 1707.895702\n",
      "Generation  19: best fitness = 1739.254705, global best = 1739.254705\n",
      "Generation  20: best fitness = 1739.254705, global best = 1739.254705\n",
      "Generation  21: best fitness = 1757.990742, global best = 1757.990742\n",
      "Generation  22: best fitness = 1757.990742, global best = 1757.990742\n",
      "Generation  23: best fitness = 1757.990742, global best = 1757.990742\n",
      "Generation  24: best fitness = 1766.206506, global best = 1766.206506\n",
      "Generation  25: best fitness = 1778.765079, global best = 1778.765079\n",
      "Generation  26: best fitness = 1831.729144, global best = 1831.729144\n",
      "Generation  27: best fitness = 1834.846774, global best = 1834.846774\n",
      "Generation  28: best fitness = 1834.846774, global best = 1834.846774\n",
      "Generation  29: best fitness = 1834.846774, global best = 1834.846774\n",
      "Generation  30: best fitness = 1834.846774, global best = 1834.846774\n",
      "\n",
      "Best fitness found: 1834.846774\n",
      "\n",
      "=== Discovered Rule List (ordered) ===\n",
      "\n",
      "Rule 1: IF rob_hurst_100 > -0.7727\n",
      "        THEN BUY with TP = 9.9%, SL = 2.6%, Capital Fraction = 30.0%\n",
      "\n",
      "Rule 2: IF cand_close_open_ratio_1 < -0.1840\n",
      "        THEN SELL with TP = 4.0%, SL = 1.0%, Capital Fraction = 20.3%\n",
      "\n",
      "Rule 3: IF cand_range_1 > -1.1037\n",
      "        THEN SELL with TP = 8.9%, SL = 2.9%, Capital Fraction = 30.0%\n",
      "\n",
      "Train final equity: 1996.46, Number of positions: 79\n",
      "Test  final equity: 852.18, Number of positions: 51\n",
      "Best rules exported to rules_G09.json\n"
     ]
    }
   ],
   "source": [
    "best_chrom, best_fit = run_ga(df, FEATURE_COLS)\n",
    "print(f\"\\nBest fitness found: {best_fit:.6f}\")\n",
    "\n",
    "    # 3) Show the final rule list\n",
    "best_rules = decode_chromosome(best_chrom, df, FEATURE_COLS)\n",
    "pretty_print_rules(best_chrom, df, FEATURE_COLS)\n",
    "\n",
    "    # 4) Evaluate on TRAIN and TEST (3-month out-of-sample)\n",
    "train_returns, final_train_eq = backtest_rule_list(best_rules, df, FEATURE_COLS)\n",
    "test_returns, final_test_eq  = backtest_rule_list(best_rules, df_test,  FEATURE_COLS)\n",
    "\n",
    "print(f\"Train final equity: {final_train_eq:.2f}, Number of positions: {len(train_returns)}\")\n",
    "print(f\"Test  final equity: {final_test_eq:.2f}, Number of positions: {len(test_returns)}\")\n",
    "    \n",
    "rules_json = {\"rules\": []}\n",
    "for rule in best_rules:\n",
    "    rule_dict = {\"conditions\": [], \"action\": {}}\n",
    "    for cond in rule.conditions:\n",
    "        feat_name = FEATURE_COLS[cond.feature_idx]\n",
    "        rule_dict[\"conditions\"].append({ \"feature\": feat_name, \"op\": cond.operator, \"threshold\": cond.threshold })\n",
    "    rule_dict[\"action\"] = {\n",
    "        \"side\": rule.side,\n",
    "        \"tp\": rule.tp,\n",
    "        \"sl\": rule.sl,\n",
    "        \"size\": rule.size_frac\n",
    "    }\n",
    "    rules_json[\"rules\"].append(rule_dict)\n",
    "with open(\"rules_G09.json\", \"w\") as f:\n",
    "        json.dump(rules_json, f, indent=4)\n",
    "print(\"Best rules exported to rules_G09.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
